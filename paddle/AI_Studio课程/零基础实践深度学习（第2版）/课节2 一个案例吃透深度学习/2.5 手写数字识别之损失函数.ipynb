{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 手写数字识别之损失函数\n",
    "\n",
    "**第2.4节**我们尝试通过更复杂的模型（经典的全连接神经网络和卷积神经网络），提升手写数字识别模型训练的准确性。本节我们继续将“横纵式”教学法从横向展开，如 **图1** 所示，探讨损失函数的优化对模型训练效果的影响。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/c59e974d760e47feb76dfaa749f4234c5f86909407694ae0bc5c05d6802932ba\" width=\"1200\" hegiht=\"\" ></center>\n",
    "<center><br>图1：“横纵式”教学法 — 损失函数优化 </br></center>\n",
    "<br></br>\n",
    "\n",
    "\n",
    "损失函数是模型优化的目标，用于在众多的参数取值中，识别最理想的取值。损失函数的计算在训练过程的代码中，每一轮模型训练的过程都相同，分如下3步：1）先根据输入数据正向计算预测输出；2）再根据预测值和真实值计算损失；3）最后根据损失反向传播梯度并更新参数。\n",
    "\n",
    "## 2.5.1 分类任务的损失函数\n",
    "\n",
    "在**第2.4节**我们复用了房价预测模型的损失函数：均方误差。从预测效果来看，虽然损失不断下降，模型的预测值逐渐逼近真实值，但模型的最终效果不够理想。究其根本，不同的深度学习任务需要有各自适宜的损失函数。我们以房价预测和手写数字识别两个任务为例，详细剖析其中的缘由有如下3点：\n",
    "\n",
    "（1）房价预测是回归任务，而手写数字识别是分类任务，使用均方误差作为分类任务的损失函数存在逻辑和效果上的缺欠。\n",
    "\n",
    "（2）房价可以是大于0的任何浮点数，而手写数字识别的输出只可能是0~9之间的10个整数，相当于一种标签。\n",
    "\n",
    "（3）在房价预测的案例中，由于房价本身是一个连续的实数值，因此以模型输出的数值和真实房价差距作为损失函数是符合道理的。但对于分类问题，真实结果是分类标签，而模型输出是实数值，导致以两者相减作为损失不具备物理含义。\n",
    "\n",
    "那么，什么是分类任务的合理输出呢？分类任务本质上是“某种特征组合下的分类概率”，下面以一个简单案例说明，如 **图2** 所示。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/c9f479c2960140839b259ca7ab2256a0dcd7a714e76a4edfb5377f1566796460\" width=\"700\" hegiht=\"\" ></center>\n",
    "<center><br>图2：观测数据和背后规律之间的关系 </br></center>\n",
    "<br></br>\n",
    "\n",
    "\n",
    "在本案例中，医生根据肿瘤大小$x$作为肿瘤性质$y$的参考判断（判断的因素有很多，肿瘤大小只是其中之一），那么我们观测到该模型判断的结果是$x$和$y$的标签（1为恶性，0为良性）。而这个数据背后的规律是不同大小的肿瘤，属于恶性肿瘤的概率。观测数据是真实规律抽样下的结果，分类模型应该拟合这个真实规律，输出属于该分类标签的概率。\n",
    "\n",
    "## 2.5.2 Softmax函数\n",
    "\n",
    "如果模型能输出10个标签的概率，对应真实标签的概率输出尽可能接近100%，而其他标签的概率输出尽可能接近0%，且所有输出概率之和为1。这是一种更合理的假设！与此对应，真实的标签值可以转变成一个10维度的one-hot向量，在对应数字的位置上为1，其余位置为0，比如标签“6”可以转变成[0,0,0,0,0,0,1,0,0,0]。\n",
    "\n",
    "为了实现上述思路，需要引入Softmax函数，它可以将原始输出转变成对应标签的概率，公式如下，其中$C$是标签类别个数。\n",
    "\n",
    "$$softmax(x_i) = \\frac {e^{x_i}}{\\sum_{j=0}^N{e^{x_j}}}, i=0, ..., C-1$$ \n",
    "\n",
    "从公式的形式可见，每个输出的范围均在0~1之间，且所有输出之和等于1，这是这种变换后可被解释成概率的基本前提。对应到代码上，需要在前向计算中，对全连接网络的输出层增加一个Softmax运算，`outputs = F.softmax(outputs)`。\n",
    "\n",
    "**图3** 是一个三个标签的分类模型（三分类）使用的Softmax输出层，从中可见原始输出的三个数字3、1、-3，经过Softmax层后转变成加和为1的三个概率值0.88、0.12、0。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/ef129caf64254318821e9410bb71ab1f45fff20e4282482986081d44a1e3bcbb\" width=\"600\" hegiht=\"\" ></center>\n",
    "<center><br>图3：网络输出层改为softmax函数 </br></center>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上文解释了为何让分类模型的输出拟合概率的原因，但为何偏偏用Softmax函数完成这个职能？ 下面以二分类问题（只输出两个标签）进行原理的探讨。\n",
    "\n",
    "对于二分类问题，使用两个输出接入Softmax作为输出层，等价于使用单一输出接入Sigmoid函数。如 **图4** 所示，利用两个标签的输出概率之和为1的条件，Softmax输出0.6和0.4两个标签概率，从数学上等价于输出一个标签的概率0.6。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/4dbdf378438f42b0bc6de6f11955834b7063cc6916544017b0af2ccf1f730984\" width=\"400\" hegiht=\"\" ></center>\n",
    "<center><br>图4：对于二分类问题，等价于单一输出接入Sigmoid函数 </br></center>\n",
    "<br></br>\n",
    "\n",
    "在这种情况下，只有一层的模型为$S(w^{T}x_i)$，$S$为Sigmoid函数。模型预测为1的概率为$S(w^{T}x_i)$，模型预测为0的概率为$1-S(w^{T}x_i)$。\n",
    "\n",
    "**图5** 是肿瘤大小和肿瘤性质的数据图。从图中可发现，往往尺寸越大的肿瘤几乎全部是恶性，尺寸极小的肿瘤几乎全部是良性。只有在中间区域，肿瘤的恶性概率会从0逐渐到1（绿色区域），这种数据的分布是符合多数现实问题的规律。如果我们直接线性拟合，相当于红色的直线，会发现直线的纵轴0-1的区域会拉的很长，而我们期望拟合曲线0-1的区域与真实的分类边界区域重合。那么，观察下Sigmoid的曲线趋势可以满足我们对个问题的一切期望，它的概率变化会集中在一个边界区域，有助于模型提升边界区域的分辨率。\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/bbf5e0eda62c44bb84528dbfd8642ef901b2dc42c6f541bc8cd0b75b967dc934\" width=\"900\" hegiht=\"\" ></center>\n",
    "<center><br>图5：使用Sigmoid拟合输出可提高分类模型对边界的分辨率 </br></center>\n",
    "<br></br>\n",
    "\n",
    "这就类似于公共区域使用的带有恒温装置的热水器温度阀门，如 **图6** 所示。由于人体适应的水温在34度-42度之间，我们更期望阀门的水温条件集中在这个区域，而不是在0-100度之间线性分布。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/9d05d75c9db44d95b8cdec6fe1615e24d9a24c0ce4f64954a2a5659aaaa7437b\" width=\"400\" hegiht=\"\" ></center>\n",
    "<center><br>图6：热水器水温控制 </br></center>\n",
    "<br></br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5.2 交叉熵函数\n",
    "\n",
    "在模型输出为分类标签的概率时，直接以标签和概率做比较也不够合理，人们更习惯使用交叉熵误差作为分类问题的损失衡量。交叉熵损失函数的设计是基于最大似然思想：最大概率得到观察结果的假设是真的。如何理解呢？举个例子来说，如 **图7** 所示。有两个外形相同的盒子，甲盒中有99个白球，1个蓝球；乙盒中有99个蓝球，1个白球。一次试验取出了一个蓝球，请问这个球应该是从哪个盒子中取出的？\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/ee18a74f31524c999ea1c50f2eea31e34eee2d29f9d14d0f98e7aaa6e6f64d20\" width=\"600\" hegiht=\"\" ></center>\n",
    "<center><br>图7：体会最大似然的思想 </br></center>\n",
    "<br></br>\n",
    "\n",
    "相信大家简单思考后均会得出更可能是从乙盒中取出的，因为从乙盒中取出一个蓝球的概率更高$（P(D|h)）$，所以观察到一个蓝球更可能是从乙盒中取出的$(P(h|D))$。$D$是观测的数据，即蓝球白球；$h$是模型，即甲盒乙盒。这就是贝叶斯公式所表达的思想：\n",
    "\n",
    "$$P(h|D) ∝ P(h) \\cdot P(D|h)$$\n",
    "\n",
    "依据贝叶斯公式，某二分类模型“生成”$N$个训练样本的概率：\n",
    "\n",
    "$$P(x_1)\\cdot S(w^{T}x_1)\\cdot P(x_2)\\cdot(1-S(w^{T}x_2))\\cdot … \\cdot P(x_n)\\cdot S(w^{T}x_N)$$\n",
    "\n",
    "------\n",
    "**说明：**\n",
    "\n",
    "对于二分类问题，模型为$S(w^{T}x_i)$，$S$为Sigmoid函数。当$y_i$=1，概率为$S(w^{T}x_i)$；当$y_i$=0，概率为$1-S(w^{T}x_i)$。\n",
    "\n",
    "------\n",
    "\n",
    "经过公式推导，使得上述概率最大等价于最小化交叉熵，得到交叉熵的损失函数。交叉熵的公式如下：\n",
    "\n",
    "$$ Loss = -[\\sum_{k=1}^{N} t_k\\log y_k +(1- t_k)\\log(1-y_k)] $$\n",
    "  \n",
    "其中，$\\log$表示以$e$为底数的自然对数。$y_k$代表模型输出，$t_k$代表各个标签。$t_k$中只有正确解的标签为1，其余均为0（one-hot表示）。\n",
    "\n",
    "因此，交叉熵只计算对应着“正确解”标签的输出的自然对数。比如，假设正确标签的索引是“2”，与之对应的神经网络的输出是0.6，则交叉熵误差是$−\\log 0.6 = 0.51$；若“2”对应的输出是0.1，则交叉熵误差为$−\\log 0.1 = 2.30$。由此可见，交叉熵误差的值是由正确标签所对应的输出结果决定的。\n",
    "\n",
    "自然对数的函数曲线可由如下代码实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "x = np.arange(0.01,1,0.01)\n",
    "y = np.log(x)\n",
    "plt.title(\"y=log(x)\") \n",
    "plt.xlabel(\"x\") \n",
    "plt.ylabel(\"y\") \n",
    "plt.plot(x,y)\n",
    "plt.show()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如自然对数的图形所示，当$x$等于1时，$y$为0；随着$x$向0靠近，$y$逐渐变小。因此，正确解标签对应的输出越大，交叉熵的值越接近0；当输出为1时，交叉熵误差为0。反之，如果正确解标签对应的输出越小，则交叉熵的值越大。\n",
    "\n",
    "## 2.5.3 交叉熵函数的代码实现\n",
    "\n",
    "在手写数字识别任务中，通过如下修改就可以将在现有模型的损失函数替换成交叉熵：\n",
    "\n",
    "1）网络定义部分，将输出层改成“输出十个标签的概率”的模式。\n",
    "\n",
    "2）在训练过程部分，将损失函数从均方误差换成交叉熵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在数据处理部分，同之前一样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data_process import get_MNIST_dataloader\n",
    "\n",
    "train_loader, test_loader = get_MNIST_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在网络定义部分，需要修改输出层结构，代码如下所示。\n",
    "\n",
    "- 从：self.fc = Linear(in_features=980, out_features=1)\n",
    "- 到：self.fc = Linear(in_features=980, out_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义 SimpleNet 网络结构\n",
    "import paddle\n",
    "from paddle.nn import Conv2D, MaxPool2D, Linear\n",
    "import paddle.nn.functional as F\n",
    "# 多层卷积神经网络实现\n",
    "class MNIST(paddle.nn.Layer):\n",
    "     def __init__(self):\n",
    "         super(MNIST, self).__init__()\n",
    "         \n",
    "         # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\n",
    "         self.conv1 = Conv2D(in_channels=1, out_channels=20, kernel_size=5, stride=1, padding=2)\n",
    "         # 定义池化层，池化核的大小kernel_size为2，池化步长为2\n",
    "         self.max_pool1 = MaxPool2D(kernel_size=2, stride=2)\n",
    "         # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\n",
    "         self.conv2 = Conv2D(in_channels=20, out_channels=20, kernel_size=5, stride=1, padding=2)\n",
    "         # 定义池化层，池化核的大小kernel_size为2，池化步长为2\n",
    "         self.max_pool2 = MaxPool2D(kernel_size=2, stride=2)\n",
    "         # 定义一层全连接层，输出维度是10\n",
    "         self.fc = Linear(in_features=980, out_features=10)\n",
    "         \n",
    "    # 定义网络前向计算过程，卷积后紧接着使用池化层，最后使用全连接层计算最终输出\n",
    "    # 卷积层激活函数使用Relu，全连接层激活函数使用softmax\n",
    "     def forward(self, inputs):\n",
    "         x = self.conv1(inputs)\n",
    "         x = F.relu(x)\n",
    "         x = self.max_pool1(x)\n",
    "         x = self.conv2(x)\n",
    "         x = F.relu(x)\n",
    "         x = self.max_pool2(x)\n",
    "         x = paddle.reshape(x, [x.shape[0], 980])\n",
    "         x = self.fc(x)\n",
    "         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改计算损失的函数，从均方误差（常用于回归问题）到交叉熵误差（常用于分类问题），代码如下所示。\n",
    "\n",
    "- 从：loss = paddle.nn.functional.square_error_cost(predict, label)\n",
    "- 到：loss = paddle.nn.functional.cross_entropy(predict, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluation(model, datasets):\n",
    "    model.eval()\n",
    "\n",
    "    acc_set = list()\n",
    "    for batch_id, data in enumerate(datasets()):\n",
    "        images, labels = data\n",
    "        images = paddle.to_tensor(images)\n",
    "        labels = paddle.to_tensor(labels)\n",
    "        pred = model(images)   # 获取预测值\n",
    "        acc = paddle.metric.accuracy(input=pred, label=labels)\n",
    "        acc_set.extend(acc.numpy())\n",
    "    \n",
    "    # #计算多个batch的准确率\n",
    "    acc_val_mean = np.array(acc_set).mean()\n",
    "    return acc_val_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0622 19:15:00.799525   101 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 11.2, Runtime API Version: 11.2\n",
      "W0622 19:15:00.803115   101 device_context.cc:465] device: 0, cuDNN Version: 8.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss is: [2.9631767]\n",
      "epoch: 0, batch: 200, loss is: [0.28771558]\n",
      "epoch: 0, batch: 400, loss is: [0.17397963]\n",
      "epoch: 0, batch: 600, loss is: [0.1328078]\n",
      "epoch: 0, batch: 800, loss is: [0.22312419]\n",
      "epoch: 1, batch: 0, loss is: [0.1861222]\n",
      "epoch: 1, batch: 200, loss is: [0.10068697]\n",
      "epoch: 1, batch: 400, loss is: [0.14453436]\n",
      "epoch: 1, batch: 600, loss is: [0.10306983]\n",
      "epoch: 1, batch: 800, loss is: [0.06579047]\n",
      "epoch: 2, batch: 0, loss is: [0.05550075]\n",
      "epoch: 2, batch: 200, loss is: [0.0553881]\n",
      "epoch: 2, batch: 400, loss is: [0.14965281]\n",
      "epoch: 2, batch: 600, loss is: [0.05848636]\n",
      "epoch: 2, batch: 800, loss is: [0.06287296]\n",
      "epoch: 3, batch: 0, loss is: [0.10332403]\n",
      "epoch: 3, batch: 200, loss is: [0.2565148]\n",
      "epoch: 3, batch: 400, loss is: [0.03804234]\n",
      "epoch: 3, batch: 600, loss is: [0.07710356]\n",
      "epoch: 3, batch: 800, loss is: [0.05255894]\n",
      "epoch: 4, batch: 0, loss is: [0.03155422]\n",
      "epoch: 4, batch: 200, loss is: [0.02072622]\n",
      "epoch: 4, batch: 400, loss is: [0.07428185]\n",
      "epoch: 4, batch: 600, loss is: [0.09284233]\n",
      "epoch: 4, batch: 800, loss is: [0.03468031]\n",
      "epoch: 5, batch: 0, loss is: [0.02539857]\n",
      "epoch: 5, batch: 200, loss is: [0.08541536]\n",
      "epoch: 5, batch: 400, loss is: [0.03187229]\n",
      "epoch: 5, batch: 600, loss is: [0.04895028]\n",
      "epoch: 5, batch: 800, loss is: [0.03515094]\n",
      "epoch: 6, batch: 0, loss is: [0.01478073]\n",
      "epoch: 6, batch: 200, loss is: [0.00694395]\n",
      "epoch: 6, batch: 400, loss is: [0.07129884]\n",
      "epoch: 6, batch: 600, loss is: [0.16983847]\n",
      "epoch: 6, batch: 800, loss is: [0.09051609]\n",
      "epoch: 7, batch: 0, loss is: [0.04717643]\n",
      "epoch: 7, batch: 200, loss is: [0.00741225]\n",
      "epoch: 7, batch: 400, loss is: [0.07615365]\n",
      "epoch: 7, batch: 600, loss is: [0.03185874]\n",
      "epoch: 7, batch: 800, loss is: [0.26657808]\n",
      "epoch: 8, batch: 0, loss is: [0.051815]\n",
      "epoch: 8, batch: 200, loss is: [0.13424751]\n",
      "epoch: 8, batch: 400, loss is: [0.02104561]\n",
      "epoch: 8, batch: 600, loss is: [0.02238336]\n",
      "epoch: 8, batch: 800, loss is: [0.01337203]\n",
      "epoch: 9, batch: 0, loss is: [0.04752279]\n",
      "epoch: 9, batch: 200, loss is: [0.02498975]\n",
      "epoch: 9, batch: 400, loss is: [0.0057624]\n",
      "epoch: 9, batch: 600, loss is: [0.0295256]\n",
      "epoch: 9, batch: 800, loss is: [0.06521191]\n"
     ]
    }
   ],
   "source": [
    "#仅修改计算损失的函数，从均方误差（常用于回归问题）到交叉熵误差（常用于分类问题）\n",
    "def train(model):\n",
    "    model.train()\n",
    "    #调用加载数据的函数\n",
    "    # train_loader = load_data('train')\n",
    "    # val_loader = load_data('valid')\n",
    "    opt = paddle.optimizer.SGD(learning_rate=0.01, parameters=model.parameters())\n",
    "    EPOCH_NUM = 10\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #准备数据\n",
    "            images, labels = data\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.to_tensor(labels)\n",
    "            #前向计算的过程\n",
    "            predicts = model(images)\n",
    "            \n",
    "            #计算损失，使用交叉熵损失函数，取一个批次样本损失的平均值\n",
    "            loss = F.cross_entropy(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "            \n",
    "            #每训练了200批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 200 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}\".format(epoch_id, batch_id, avg_loss.numpy()))\n",
    "            \n",
    "            #后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            # 最小化loss,更新参数\n",
    "            opt.step()\n",
    "            # 清除梯度\n",
    "            opt.clear_grad()\n",
    "        # acc_train_mean = evaluation(model, train_loader)\n",
    "        # acc_val_mean = evaluation(model, val_loader)\n",
    "        # print('train_acc: {}, val acc: {}'.format(acc_train_mean, acc_val_mean))   \n",
    "    #保存模型参数\n",
    "    paddle.save(model.state_dict(), 'mnist.pdparams')\n",
    "    \n",
    "#创建模型    \n",
    "model = MNIST()\n",
    "#启动训练过程\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然上述训练过程的损失明显比使用均方误差算法要小，但因为损失函数量纲的变化，我们无法从比较两个不同的损失函数得出谁更加优秀。怎么解决这个问题呢？我们可以回归到问题的本质，谁的分类准确率更高来判断。在后面介绍完计算准确率和作图的内容后，读者可以自行测试采用不同损失函数下，模型准确率的高低。\n",
    "\n",
    "至此，大家阅读论文中常见的一些分类任务模型图就清晰明了，如全连接神经网络、卷积神经网络，在模型的最后阶段，都是使用Softmax进行处理。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/23f506ae9d7543faad4847574a6e9b3dc9a1cb0527ea4dc6ad0150f14a7c53a0\" width=\"1000\" hegiht=\"\" ></center>\n",
    "<center><br>图8：常见的分类任务模型图</br></center>\n",
    "<br></br>\n",
    "\n",
    "由于我们修改了模型的输出格式，因此使用模型做预测时的代码也需要做相应的调整。从模型输出10个标签的概率中选择最大的，将其标签编号输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本次预测的数字是:  0\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# 读取一张本地的样例图片，转变成模型输入的格式\n",
    "def load_image(img_path):\n",
    "    # 从img_path中读取图像，并转为灰度图\n",
    "    im = Image.open(img_path).convert('L')\n",
    "    im = im.resize((28, 28), Image.ANTIALIAS)\n",
    "    im = np.array(im).reshape(1, 1, 28, 28).astype(np.float32)\n",
    "    # 图像归一化\n",
    "    im = 1.0 - im / 255.\n",
    "    return im\n",
    "\n",
    "# 定义预测过程\n",
    "model = MNIST()\n",
    "params_file_path = 'mnist.pdparams'\n",
    "img_path = 'work/example_0.jpg'\n",
    "# 加载模型参数\n",
    "param_dict = paddle.load(params_file_path)\n",
    "model.load_dict(param_dict)\n",
    "# 灌入数据\n",
    "model.eval()\n",
    "tensor_img = load_image(img_path)\n",
    "#模型反馈10个分类标签的对应概率\n",
    "results = model(paddle.to_tensor(tensor_img))\n",
    "#取概率最大的标签作为预测输出\n",
    "lab = np.argsort(results.numpy())\n",
    "print(\"本次预测的数字是: \", lab[0][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作业 2-2\n",
    "\n",
    "预习下对于计算机视觉任务，有哪些常见的卷积神经网络（如LeNet-5、AlexNet等）？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
