{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.8 手写数字识别之训练调试与优化\n",
    "\n",
    "**第2.7节**我们研究了资源部署优化的方法，通过使用单GPU和分布式部署，提升模型训练的效率。本节我们依旧横向展开\"横纵式\"，如 **图1** 所示，探讨在手写数字识别任务中，为了保证模型的真实效果，在模型训练部分，对模型进行一些调试和优化的方法。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/1b710d7d137b4aed8c82adeb73684d31ca963afe837d433384762db1376872ed\" width=\"1200\" hegiht=\"\" ></center>\n",
    "<center>图1：“横纵式”教学法 — 训练过程</center>\n",
    "<br></br>\n",
    "\n",
    "\n",
    "训练过程优化思路主要有如下五个关键环节：\n",
    "\n",
    "**（1）计算分类准确率，观测模型训练效果**\n",
    "\n",
    "交叉熵损失函数只能作为优化目标，无法直接准确衡量模型的训练效果。准确率可以直接衡量训练效果，但由于其离散性质，不适合做为损失函数优化神经网络。\n",
    "    \n",
    "**（2）检查模型训练过程，识别潜在问题**\n",
    "\n",
    "如果模型的损失或者评估指标表现异常，通常需要打印模型每一层的输入和输出来定位问题，分析每一层的内容来获取错误的原因。\n",
    "    \n",
    "**（3）加入校验或测试，更好评价模型效果**\n",
    "\n",
    "理想的模型训练结果是在训练集和验证集上均有较高的准确率，如果训练集的准确率低于验证集，说明网络训练程度不够；如果训练集的准确率高于验证集，可能是发生了过拟合现象。通过在优化目标中加入正则化项的办法，解决过拟合的问题。\n",
    "    \n",
    "**（4）加入正则化项，避免模型过拟合**\n",
    "\n",
    "飞桨框架支持为整体参数加入正则化项，这是通常的做法。此外，飞桨框架也支持为某一层或某一部分的网络单独加入正则化项，以达到精细调整参数训练的效果。\n",
    "\n",
    "**（5）可视化分析**\n",
    "\n",
    "用户不仅可以通过打印或使用matplotlib库作图，飞桨还提供了更专业的可视化分析工具VisualDL，提供便捷的可视化分析方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8.1 计算模型的分类准确率\n",
    "\n",
    "准确率是一个直观衡量分类模型效果的指标，由于这个指标是离散的，因此不适合作为损失来优化。通常情况下，交叉熵损失越小的模型，分类的准确率也越高。基于分类准确率，我们可以公平地比较两种损失函数的优劣，例如在【手写数字识别】之损失函数章节中均方误差和交叉熵的比较。\n",
    "\n",
    "使用飞桨提供的计算分类准确率API，可以直接计算准确率。\n",
    "\n",
    "> *class* paddle.metric.Accuracy\n",
    "\n",
    "该API的输入参数input为预测的分类结果predict，输入参数label为数据真实的label。飞桨还提供了更多衡量模型效果的计算指标，详细可以查看paddle.meric包下面的API。\n",
    "\n",
    "在下述代码中，我们在模型前向计算过程forward函数中计算分类准确率，并在训练时打印每个批次样本的分类准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "from data_process import get_MNIST_dataloader\n",
    "\n",
    "train_loader, test_loader = get_MNIST_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0905 14:35:13.571403    98 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 11.2, Runtime API Version: 11.2\r\n",
      "W0905 14:35:13.574612    98 device_context.cc:465] device: 0, cuDNN Version: 8.2.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss is: [3.8877463], acc is [0.09375]\r\n",
      "epoch: 0, batch: 200, loss is: [0.205946], acc is [0.921875]\r\n",
      "epoch: 0, batch: 400, loss is: [0.01945284], acc is [1.]\r\n",
      "epoch: 0, batch: 600, loss is: [0.0915114], acc is [0.96875]\r\n",
      "epoch: 0, batch: 800, loss is: [0.07086004], acc is [0.984375]\r\n",
      "epoch: 1, batch: 0, loss is: [0.06174702], acc is [0.984375]\r\n",
      "epoch: 1, batch: 200, loss is: [0.02994888], acc is [0.984375]\r\n",
      "epoch: 1, batch: 400, loss is: [0.06212441], acc is [0.96875]\r\n",
      "epoch: 1, batch: 600, loss is: [0.11327725], acc is [0.96875]\r\n",
      "epoch: 1, batch: 800, loss is: [0.03650226], acc is [0.984375]\r\n",
      "epoch: 2, batch: 0, loss is: [0.03422514], acc is [0.984375]\r\n",
      "epoch: 2, batch: 200, loss is: [0.00483766], acc is [1.]\r\n",
      "epoch: 2, batch: 400, loss is: [0.023434], acc is [0.984375]\r\n",
      "epoch: 2, batch: 600, loss is: [0.1054302], acc is [0.984375]\r\n",
      "epoch: 2, batch: 800, loss is: [0.02677589], acc is [1.]\r\n",
      "epoch: 3, batch: 0, loss is: [0.0193211], acc is [1.]\r\n",
      "epoch: 3, batch: 200, loss is: [0.07209359], acc is [0.984375]\r\n",
      "epoch: 3, batch: 400, loss is: [0.07815815], acc is [0.96875]\r\n",
      "epoch: 3, batch: 600, loss is: [0.03945119], acc is [0.984375]\r\n",
      "epoch: 3, batch: 800, loss is: [0.17180261], acc is [0.9375]\r\n",
      "epoch: 4, batch: 0, loss is: [0.10021097], acc is [0.96875]\r\n",
      "epoch: 4, batch: 200, loss is: [0.04378257], acc is [0.984375]\r\n",
      "epoch: 4, batch: 400, loss is: [0.02809021], acc is [0.984375]\r\n",
      "epoch: 4, batch: 600, loss is: [0.04106805], acc is [0.984375]\r\n",
      "epoch: 4, batch: 800, loss is: [0.01189358], acc is [1.]\r\n"
     ]
    }
   ],
   "source": [
    "# 定义模型结构\n",
    "import paddle.nn.functional as F\n",
    "from paddle.nn import Conv2D, MaxPool2D, Linear\n",
    "\n",
    "# 多层卷积神经网络实现\n",
    "class MNIST(paddle.nn.Layer):\n",
    "     def __init__(self):\n",
    "         super(MNIST, self).__init__()\n",
    "         \n",
    "         # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\n",
    "         self.conv1 = Conv2D(in_channels=1, out_channels=20, kernel_size=5, stride=1, padding=2)\n",
    "         # 定义池化层，池化核的大小kernel_size为2，池化步长为2\n",
    "         self.max_pool1 = MaxPool2D(kernel_size=2, stride=2)\n",
    "         # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\n",
    "         self.conv2 = Conv2D(in_channels=20, out_channels=20, kernel_size=5, stride=1, padding=2)\n",
    "         # 定义池化层，池化核的大小kernel_size为2，池化步长为2\n",
    "         self.max_pool2 = MaxPool2D(kernel_size=2, stride=2)\n",
    "         # 定义一层全连接层，输出维度是10\n",
    "         self.fc = Linear(in_features=980, out_features=10)\n",
    "         \n",
    "   # 定义网络前向计算过程，卷积后紧接着使用池化层，最后使用全连接层计算最终输出\n",
    "   # 卷积层激活函数使用Relu，全连接层激活函数使用softmax\n",
    "     def forward(self, inputs, label):\n",
    "         x = self.conv1(inputs)\n",
    "         x = F.relu(x)\n",
    "         x = self.max_pool1(x)\n",
    "         x = self.conv2(x)\n",
    "         x = F.relu(x)\n",
    "         x = self.max_pool2(x)\n",
    "         x = paddle.reshape(x, [x.shape[0], 980])\n",
    "         x = self.fc(x)\n",
    "         if label is not None:\n",
    "             acc = paddle.metric.accuracy(input=x, label=label)\n",
    "             return x, acc\n",
    "         else:\n",
    "             return x\n",
    "\n",
    "#在使用GPU机器时，可以将use_gpu变量设置成True\n",
    "use_gpu = True\n",
    "paddle.set_device('gpu:0') if use_gpu else paddle.set_device('cpu')\n",
    "\n",
    "#仅优化算法的设置有所差别\n",
    "def train(model):\n",
    "    model = MNIST()\n",
    "    model.train()\n",
    "    \n",
    "    #四种优化算法的设置方案，可以逐一尝试效果\n",
    "    # opt = paddle.optimizer.SGD(learning_rate=0.01, parameters=model.parameters())\n",
    "    # opt = paddle.optimizer.Momentum(learning_rate=0.01, momentum=0.9, parameters=model.parameters())\n",
    "    # opt = paddle.optimizer.Adagrad(learning_rate=0.01, parameters=model.parameters())\n",
    "    opt = paddle.optimizer.Adam(learning_rate=0.01, parameters=model.parameters())\n",
    "    \n",
    "    EPOCH_NUM = 5\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #准备数据\n",
    "            images, labels = data\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.to_tensor(labels)\n",
    "            \n",
    "            #前向计算的过程\n",
    "            predicts, acc = model(images, labels)\n",
    "            \n",
    "            #计算损失，取一个批次样本损失的平均值\n",
    "            loss = F.cross_entropy(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "            \n",
    "            #每训练了100批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 200 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}, acc is {}\".format(epoch_id, batch_id, avg_loss.numpy(), acc.numpy()))\n",
    "                \n",
    "            #后向传播，更新参数，消除梯度的过程\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "    #保存模型参数\n",
    "    paddle.save(model.state_dict(), 'mnist.pdparams')\n",
    "    \n",
    "#创建模型    \n",
    "model = MNIST()\n",
    "#启动训练过程\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8.2 检查模型训练过程，识别潜在训练问题\n",
    "\n",
    "使用飞桨动态图编程可以方便的查看和调试训练的执行过程。在网络定义的Forward函数中，可以打印每一层输入输出的尺寸，以及每层网络的参数。通过查看这些信息，不仅可以更好地理解训练的执行过程，还可以发现潜在问题，或者启发继续优化的思路。\n",
    "\n",
    "在下述程序中，使用``check_shape``变量控制是否打印“尺寸”，验证网络结构是否正确。使用``check_content``变量控制是否打印“内容值”，验证数据分布是否合理。假如在训练中发现中间层的部分输出持续为0，说明该部分的网络结构设计存在问题，没有充分利用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "########## print network layer's superparams ##############\r\n",
      "conv1-- kernel_size:[20, 1, 5, 5], padding:2, stride:[1, 1]\r\n",
      "conv2-- kernel_size:[20, 20, 5, 5], padding:2, stride:[1, 1]\r\n",
      "fc-- weight_size:[980, 10], bias_size_[10]\r\n",
      "\r\n",
      "########## print shape of features of every layer ###############\r\n",
      "inputs_shape: [64, 1, 28, 28]\r\n",
      "outputs1_shape: [64, 20, 28, 28]\r\n",
      "outputs2_shape: [64, 20, 28, 28]\r\n",
      "outputs3_shape: [64, 20, 14, 14]\r\n",
      "outputs4_shape: [64, 20, 14, 14]\r\n",
      "outputs5_shape: [64, 20, 14, 14]\r\n",
      "outputs6_shape: [64, 980]\r\n",
      "outputs7_shape: [64, 10]\r\n",
      "epoch: 0, batch: 0, loss is: [3.1953034], acc is [0.109375]\r\n",
      "epoch: 0, batch: 200, loss is: [0.37904966], acc is [0.875]\r\n",
      "epoch: 0, batch: 400, loss is: [0.16234186], acc is [0.984375]\r\n",
      "\r\n",
      "########## print convolution layer's kernel ###############\r\n",
      "conv1 params -- kernel weights: Tensor(shape=[5, 5], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\r\n",
      "       [[-0.06305157, -0.24847564, -0.63125026,  0.16255459,  0.05321766],\r\n",
      "        [ 0.27163783,  0.03359267, -0.16793424, -0.33206284,  0.24191348],\r\n",
      "        [-0.01796198,  0.59920996, -0.19074094,  0.30350232, -0.13594414],\r\n",
      "        [-0.17397462, -0.28396046,  0.37263221, -0.46014515,  0.00446801],\r\n",
      "        [-0.34503123,  0.21267484,  0.12081132,  0.25961810, -0.29448596]])\r\n",
      "conv2 params -- kernel weights: Tensor(shape=[5, 5], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\r\n",
      "       [[ 0.11260822,  0.07491580, -0.00697492,  0.03264738, -0.02312732],\r\n",
      "        [-0.13066202, -0.02998639,  0.01296079,  0.07414430, -0.07227730],\r\n",
      "        [ 0.00029436,  0.01291541,  0.06429236,  0.09252947, -0.00228186],\r\n",
      "        [-0.04436536, -0.02769227, -0.03541787, -0.04839976,  0.00429312],\r\n",
      "        [ 0.11987270, -0.00784257, -0.12884265,  0.03420701,  0.04363669]])\r\n",
      "\r\n",
      "The 13th channel of conv1 layer:  Tensor(shape=[28, 28], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\r\n",
      "       [[ 1.57676303,  1.95776081,  2.93419218,  2.93419218,  2.93419218,\r\n",
      "          2.93419218,  2.93419218,  2.93419218,  2.93419218,  2.93419218,\r\n",
      "          2.91577220,  2.16091633,  2.85406709,  2.99108791,  2.88631725,\r\n",
      "          2.31296110,  2.51821899,  2.93419218,  2.93419218,  2.93419218,\r\n",
      "          2.93419218,  2.93419218,  2.93419218,  2.93419218,  2.93419218,\r\n",
      "          2.93419218,  2.34963346,  1.86924219],\r\n",
      "        [ 1.08333588,  1.31429052,  2.38950634,  2.38950634,  2.38950634,\r\n",
      "          2.38950634,  2.38950634,  2.38950634,  2.38950634,  2.38950634,\r\n",
      "          2.14806008,  1.63691866,  1.36268055,  2.06326914,  1.71009457,\r\n",
      "          1.37815464,  1.70312703,  2.38950634,  2.38950634,  2.38950634,\r\n",
      "          2.38950634,  2.38950634,  2.38950634,  2.38950634,  2.38950634,\r\n",
      "          2.38950634,  1.93476129,  1.18708980],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          1.75884020,  1.10431981,  0.47565344,  0.36457911,  0.36683619,\r\n",
      "         -0.24916060,  1.07208598,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.24922800,  2.15712929,\r\n",
      "          1.40624642,  1.10192263, -0.09191853,  1.02681065,  0.71380407,\r\n",
      "         -0.26615554,  0.88099998,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.24922800,  1.91079450,\r\n",
      "          1.39493752,  0.80995464,  0.43273729,  1.30079973,  0.81360227,\r\n",
      "         -0.48203713,  1.00590825,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.24922800,  1.52741933,\r\n",
      "          1.33734488,  0.25015768,  0.75935733,  0.79944927,  0.12423642,\r\n",
      "         -0.53146976,  1.37331486,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.10493994,  1.42406499,\r\n",
      "          0.98795116,  0.28319174,  0.75196189,  0.68844956, -0.38671809,\r\n",
      "         -0.05348028,  1.60190117,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  1.59816170,  1.50172329,\r\n",
      "          0.52018815,  0.77675128,  0.56555337,  0.43517646, -0.15623565,\r\n",
      "          0.64870793,  2.00834846,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.21238852,  1.48406279,  1.13921022,\r\n",
      "          0.24294551,  1.07210708,  0.85704976,  0.59652609,  0.02141927,\r\n",
      "          1.17699194,  2.11901641,  2.24922800,  2.23387814,  2.21114826,\r\n",
      "          2.26930523,  2.23946428,  2.24117732,  2.20948529,  2.24922800,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  1.94132292,  1.33064198,  0.96160889,\r\n",
      "          0.21429360,  0.90007955,  0.48074329,  0.37961787,  0.35840136,\r\n",
      "          1.84916151,  1.90650201,  1.87639749,  1.87668121,  1.90720320,\r\n",
      "          2.11476707,  1.70299637,  1.79109490,  1.78689849,  2.24922800,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.19703865,  1.58767712,  1.44117045,  0.54131889,\r\n",
      "          1.27608991,  0.94705838,  0.78702778, -0.00550540,  0.66786128,\r\n",
      "          1.65697169,  1.68694818,  1.41576385,  1.02485096,  0.56235749,\r\n",
      "          0.82392734,  1.06733239,  1.19328809,  1.42852890,  2.10615444,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.07781339,  1.34000683,  1.11889362,  0.27471933,\r\n",
      "          1.47623479,  0.85916406,  0.61680526,  0.18591230,  0.94179547,\r\n",
      "          1.60816967,  1.01923084,  0.26310733, -1.00871885, -1.64961648,\r\n",
      "         -1.74799502, -0.56500012, -0.11494534,  0.64425594,  1.75857580,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.04542923,  1.15771973,  0.50759202,  0.51146859,\r\n",
      "          1.26443565,  0.49970740, -0.23061615,  0.20737801,  1.24177122,\r\n",
      "          0.61867607,  0.11704522, -1.18309247, -1.86321592, -2.64864135,\r\n",
      "         -2.15092444, -0.40615076, -0.21046360, -0.06328733,  1.38931787,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.01895857,  1.20511019,  0.19213691,  0.96520102,\r\n",
      "          1.20993614, -0.10926627, -0.63769650,  0.26152697,  0.80889571,\r\n",
      "          0.43630484, -0.51190078, -1.01252317, -1.22141266, -0.92500377,\r\n",
      "         -1.27499378, -0.03566729, -0.63719290, -0.55815345,  0.86095756,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.08103728,  1.33207846,  0.32678691,  1.50327933,\r\n",
      "          1.36101282, -0.01931037, -0.82734758,  0.71075332,  0.45209241,\r\n",
      "          0.18376869,  0.50610757, -0.05850399, -0.01595110,  0.70631558,\r\n",
      "          0.44142160,  0.49235320,  0.32371444, -0.64015907,  0.94643515,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.13415837,  1.39917970,  0.40137079,  1.21047711,\r\n",
      "          1.64575052, -0.64026505, -0.95968014,  0.38196012,  0.30980483,\r\n",
      "          1.04383397,  1.30899382,  0.49489254,  0.75227344,  1.33670056,\r\n",
      "         -0.00538747,  0.33196372,  0.52780706, -0.27753383,  1.06427550,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.13415837,  1.39917970,  0.40137079,  0.66018993,\r\n",
      "          1.25133741, -1.00954688, -1.06502783,  0.09167993, -0.38979325,\r\n",
      "          0.66176760,  0.72854674, -0.92299575, -1.21746361, -0.52190083,\r\n",
      "         -0.73357743,  0.63514787,  0.76305431,  0.40999895,  1.60275888,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.26616645,  1.77271414,  0.20479760,  0.52118057,\r\n",
      "          0.40886799, -1.66344965, -1.43225205, -0.79355556, -0.34276375,\r\n",
      "         -0.14710836, -0.88605988, -2.64313841, -1.92538035, -1.09827638,\r\n",
      "          0.37350184,  1.08052373,  1.03908563,  1.05349636,  1.96428621,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.31419444,  2.21908736,  0.71174645,  0.48882595,\r\n",
      "         -0.05339822, -2.11151147, -2.36140490, -2.28336740, -1.39570999,\r\n",
      "         -1.22161305, -1.81769896, -3.26750040, -2.58818293, -0.75749952,\r\n",
      "          0.85001963,  1.27202332,  0.82216030,  1.65936935,  2.16896486,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.36872053,  2.60003138,  2.00372720,  1.63323927,\r\n",
      "          0.51079810, -1.55086589, -2.29566741, -2.87223315, -1.95501006,\r\n",
      "         -1.43932581, -1.91844594, -1.64706063, -0.69995457,  0.82944649,\r\n",
      "          1.68111157,  1.02165508,  1.56998527,  2.06415415,  2.24922800,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.33795571,  2.69428396,  2.59896755,  2.45683622,\r\n",
      "          1.81639957,  0.76473731, -0.63784522, -1.01565254, -0.75288874,\r\n",
      "         -0.60530466, -0.16548987,  0.41499215,  1.10457957,  2.04215336,\r\n",
      "          1.71117508,  1.45834291,  1.94606030,  2.21686387,  2.24922800,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.26502085,  2.41706991,  2.78577375,  2.63210535,\r\n",
      "          3.03460741,  2.82415676,  1.99927461,  1.06300223,  0.81216723,\r\n",
      "          0.63649660,  1.13787198,  2.06013227,  1.77976096,  2.06383300,\r\n",
      "          1.65551925,  1.88498139,  2.22074747,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.26358509,  2.49472618,  2.76062489,\r\n",
      "          2.85604525,  3.51348352,  3.18425798,  3.57339811,  3.66163349,\r\n",
      "          3.46294165,  3.42431688,  2.42982960,  1.75492239,  1.84449077,\r\n",
      "          2.07106829,  2.20650744,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.25784230,  2.42502165,\r\n",
      "          2.47021532,  2.85130930,  2.76395893,  2.81741858,  2.62606812,\r\n",
      "          2.21221232,  2.07615185,  1.76499319,  1.93476892,  2.20055056,\r\n",
      "          2.24663901,  2.24922800,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.64583331,  1.00895524,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  2.24922800,  2.24922800,  2.24922800,  2.24922800,\r\n",
      "          2.24922800,  1.97753549,  1.24340677],\r\n",
      "        [ 0.35992554,  0.76722139,  1.66968119,  1.66968119,  1.66968119,\r\n",
      "          1.66968119,  1.66968119,  1.66968119,  1.66968119,  1.66968119,\r\n",
      "          1.66968119,  1.66968119,  1.66968119,  1.66968119,  1.66968119,\r\n",
      "          1.66968119,  1.66968119,  1.66968119,  1.66968119,  1.66968119,\r\n",
      "          1.66968119,  1.66968119,  1.66968119,  1.66968119,  1.66968119,\r\n",
      "          1.66968119,  1.78940856,  0.85205162],\r\n",
      "        [-0.05483250,  0.18032627,  0.98153108,  0.98153108,  0.98153108,\r\n",
      "          0.98153108,  0.98153108,  0.98153108,  0.98153108,  0.98153108,\r\n",
      "          0.98153108,  0.98153108,  0.98153108,  0.98153108,  0.98153108,\r\n",
      "          0.98153108,  0.98153108,  0.98153108,  0.98153108,  0.98153108,\r\n",
      "          0.98153108,  0.98153108,  0.98153108,  0.98153108,  0.98153108,\r\n",
      "          0.98153108,  1.14353645,  0.53895712]])\r\n",
      "The 7th channel of conv2 layer:  Tensor(shape=[14, 14], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\r\n",
      "       [[-0.25409293, -0.66168970, -0.57935500, -1.48868096, -2.08183002,\r\n",
      "         -1.33911610, -0.74000251, -0.34251714, -1.40074718, -0.97854525,\r\n",
      "         -0.62747008, -0.94004458, -0.28219345, -0.52894926],\r\n",
      "        [-0.94612551, -0.96789664, -1.04252434, -2.28471160, -2.93244386,\r\n",
      "         -1.15254617, -1.44253767, -1.68920648, -1.86377525, -0.58838648,\r\n",
      "         -0.94987696, -1.36445236, -0.43157944, -0.42930213],\r\n",
      "        [-1.29878235, -1.86798871, -2.97600794, -4.11553526, -3.98651719,\r\n",
      "         -2.19571638, -1.66379070, -3.86760926, -3.39402866, -2.33286405,\r\n",
      "         -3.08091831, -3.35946941, -1.95624983, -2.03968048],\r\n",
      "        [-1.25153780, -2.00924492, -3.10734200, -4.17039061, -2.85374713,\r\n",
      "         -2.35836053, -2.48791742, -3.99124980, -2.43252587, -2.60203409,\r\n",
      "         -3.37870812, -3.81301546, -2.30629706, -2.15978932],\r\n",
      "        [-1.25153780, -2.25941300, -3.56285596, -4.12135220, -2.61398172,\r\n",
      "         -2.01441407, -3.88805604, -3.53329206, -2.72950196, -2.62689519,\r\n",
      "         -3.27135372, -3.52888918, -2.05309367, -2.07169461],\r\n",
      "        [-1.25153780, -2.31347370, -4.03132582, -3.64191508, -1.99087465,\r\n",
      "         -2.01349831, -4.07500315, -3.62071300, -3.24732065, -2.62092948,\r\n",
      "         -2.39937925, -2.86055875, -1.75934064, -2.15174699],\r\n",
      "        [-1.25153780, -2.35707831, -4.15621328, -2.94248891, -2.62050080,\r\n",
      "         -3.30646777, -4.16481829, -2.22495556, -3.25909591, -3.71963644,\r\n",
      "         -4.39155340, -3.47604108, -2.06854749, -1.71817923],\r\n",
      "        [-1.25153780, -2.04121304, -3.36076713, -2.31935883, -2.85418010,\r\n",
      "         -3.33775401, -2.46969557, -1.31438315, -2.29970503, -2.37273550,\r\n",
      "         -2.13134480, -3.25790668, -1.81248474, -1.24302518],\r\n",
      "        [-1.25153780, -1.83585656, -2.24215269, -1.57363570, -1.95731795,\r\n",
      "         -2.12606430, -1.61913550,  0.14625229,  0.27586699, -1.37613702,\r\n",
      "         -1.33491802, -2.76888037, -1.42816770, -1.05165148],\r\n",
      "        [-1.25153780, -1.93787241, -1.84526920, -1.61436665, -1.42682374,\r\n",
      "         -1.92163455, -2.19398141, -0.40832922, -0.17310615, -2.74810195,\r\n",
      "         -2.24085212, -1.73986506, -1.39752030, -1.34790802],\r\n",
      "        [-1.25153780, -2.09485412, -2.13443446, -1.89533794, -2.16656852,\r\n",
      "         -1.67623806, -1.39321041, -2.12497044, -1.68666756, -0.61848652,\r\n",
      "         -0.86989164, -1.81202853, -1.64037287, -1.46816218],\r\n",
      "        [-1.26170301, -2.15879202, -2.71437883, -2.31642056, -2.33664322,\r\n",
      "         -2.05490804, -0.38206375, -0.96394157, -1.01726711, -0.82931221,\r\n",
      "         -2.17020512, -3.18042541, -1.98610282, -2.19472075],\r\n",
      "        [-1.22878456, -1.67976415, -2.47030187, -2.81020093, -2.20034075,\r\n",
      "         -2.44192600, -1.74215555, -2.20093799, -2.35509777, -2.68591475,\r\n",
      "         -2.79559898, -3.14834046, -1.86138821, -1.74327803],\r\n",
      "        [-1.04598784, -1.27783942, -1.65321481, -2.04070377, -1.74800372,\r\n",
      "         -1.64281404, -1.77025723, -2.43671608, -2.63182092, -2.57449508,\r\n",
      "         -2.40219665, -2.12657714, -1.32194364, -0.84718376]])\r\n",
      "The output of last layer: Tensor(shape=[10], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\r\n",
      "       [ 1.99937165, -2.35289693,  1.69447994, -3.71930218,  3.57330942,\r\n",
      "        -1.01217377, 10.14804745, -2.20251369,  0.63025647,  0.63188559]) \r\n",
      "\r\n",
      "epoch: 0, batch: 600, loss is: [0.0758898], acc is [0.984375]\r\n",
      "epoch: 0, batch: 800, loss is: [0.10419124], acc is [0.953125]\r\n",
      "Model has been saved.\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "# 定义模型结构\n",
    "class MNIST(paddle.nn.Layer):\n",
    "     def __init__(self):\n",
    "         super(MNIST, self).__init__()\n",
    "         \n",
    "         # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\n",
    "         self.conv1 = Conv2D(in_channels=1, out_channels=20, kernel_size=5, stride=1, padding=2)\n",
    "         # 定义池化层，池化核的大小kernel_size为2，池化步长为2\n",
    "         self.max_pool1 = MaxPool2D(kernel_size=2, stride=2)\n",
    "         # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\n",
    "         self.conv2 = Conv2D(in_channels=20, out_channels=20, kernel_size=5, stride=1, padding=2)\n",
    "         # 定义池化层，池化核的大小kernel_size为2，池化步长为2\n",
    "         self.max_pool2 = MaxPool2D(kernel_size=2, stride=2)\n",
    "         # 定义一层全连接层，输出维度是10\n",
    "         self.fc = Linear(in_features=980, out_features=10)\n",
    "     \n",
    "     #加入对每一层输入和输出的尺寸和数据内容的打印，根据check参数决策是否打印每层的参数和输出尺寸\n",
    "     # 卷积层激活函数使用Relu，全连接层激活函数使用softmax\n",
    "     def forward(self, inputs, label=None, check_shape=False, check_content=False):\n",
    "         # 给不同层的输出不同命名，方便调试\n",
    "         outputs1 = self.conv1(inputs)\n",
    "         outputs2 = F.relu(outputs1)\n",
    "         outputs3 = self.max_pool1(outputs2)\n",
    "         outputs4 = self.conv2(outputs3)\n",
    "         outputs5 = F.relu(outputs4)\n",
    "         outputs6 = self.max_pool2(outputs5)\n",
    "         outputs6 = paddle.reshape(outputs6, [outputs6.shape[0], -1])\n",
    "         outputs7 = self.fc(outputs6)\n",
    "         \n",
    "         # 选择是否打印神经网络每层的参数尺寸和输出尺寸，验证网络结构是否设置正确\n",
    "         if check_shape:\n",
    "             # 打印每层网络设置的超参数-卷积核尺寸，卷积步长，卷积padding，池化核尺寸\n",
    "             print(\"\\n########## print network layer's superparams ##############\")\n",
    "             print(\"conv1-- kernel_size:{}, padding:{}, stride:{}\".format(self.conv1.weight.shape, self.conv1._padding, self.conv1._stride))\n",
    "             print(\"conv2-- kernel_size:{}, padding:{}, stride:{}\".format(self.conv2.weight.shape, self.conv2._padding, self.conv2._stride))\n",
    "             #print(\"max_pool1-- kernel_size:{}, padding:{}, stride:{}\".format(self.max_pool1.pool_size, self.max_pool1.pool_stride, self.max_pool1._stride))\n",
    "             #print(\"max_pool2-- kernel_size:{}, padding:{}, stride:{}\".format(self.max_pool2.weight.shape, self.max_pool2._padding, self.max_pool2._stride))\n",
    "             print(\"fc-- weight_size:{}, bias_size_{}\".format(self.fc.weight.shape, self.fc.bias.shape))\n",
    "             \n",
    "             # 打印每层的输出尺寸\n",
    "             print(\"\\n########## print shape of features of every layer ###############\")\n",
    "             print(\"inputs_shape: {}\".format(inputs.shape))\n",
    "             print(\"outputs1_shape: {}\".format(outputs1.shape))\n",
    "             print(\"outputs2_shape: {}\".format(outputs2.shape))\n",
    "             print(\"outputs3_shape: {}\".format(outputs3.shape))\n",
    "             print(\"outputs4_shape: {}\".format(outputs4.shape))\n",
    "             print(\"outputs5_shape: {}\".format(outputs5.shape))\n",
    "             print(\"outputs6_shape: {}\".format(outputs6.shape))\n",
    "             print(\"outputs7_shape: {}\".format(outputs7.shape))\n",
    "             # print(\"outputs8_shape: {}\".format(outputs8.shape))\n",
    "             \n",
    "         # 选择是否打印训练过程中的参数和输出内容，可用于训练过程中的调试\n",
    "         if check_content:\n",
    "            # 打印卷积层的参数-卷积核权重，权重参数较多，此处只打印部分参数\n",
    "             print(\"\\n########## print convolution layer's kernel ###############\")\n",
    "             print(\"conv1 params -- kernel weights:\", self.conv1.weight[0][0])\n",
    "             print(\"conv2 params -- kernel weights:\", self.conv2.weight[0][0])\n",
    "\n",
    "             # 创建随机数，随机打印某一个通道的输出值\n",
    "             idx1 = np.random.randint(0, outputs1.shape[1])\n",
    "             idx2 = np.random.randint(0, outputs4.shape[1])\n",
    "             # 打印卷积-池化后的结果，仅打印batch中第一个图像对应的特征\n",
    "             print(\"\\nThe {}th channel of conv1 layer: \".format(idx1), outputs1[0][idx1])\n",
    "             print(\"The {}th channel of conv2 layer: \".format(idx2), outputs4[0][idx2])\n",
    "             print(\"The output of last layer:\", outputs7[0], '\\n')\n",
    "            \n",
    "        # 如果label不是None，则计算分类精度并返回\n",
    "         if label is not None:\n",
    "             acc = paddle.metric.accuracy(input=F.softmax(outputs7), label=label)\n",
    "             return outputs7, acc\n",
    "         else:\n",
    "             return outputs7\n",
    "\n",
    "#在使用GPU机器时，可以将use_gpu变量设置成True\n",
    "use_gpu = True\n",
    "paddle.set_device('gpu:0') if use_gpu else paddle.set_device('cpu')    \n",
    "\n",
    "def train(model):\n",
    "    model = MNIST()\n",
    "    model.train()\n",
    "    \n",
    "    #四种优化算法的设置方案，可以逐一尝试效果\n",
    "    opt = paddle.optimizer.SGD(learning_rate=0.01, parameters=model.parameters())\n",
    "    # opt = paddle.optimizer.Momentum(learning_rate=0.01, momentum=0.9, parameters=model.parameters())\n",
    "    # opt = paddle.optimizer.Adagrad(learning_rate=0.01, parameters=model.parameters())\n",
    "    # opt = paddle.optimizer.Adam(learning_rate=0.01, parameters=model.parameters())\n",
    "    \n",
    "    EPOCH_NUM = 1\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #准备数据，变得更加简洁\n",
    "            images, labels = data\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.to_tensor(labels)\n",
    "            \n",
    "            #前向计算的过程，同时拿到模型输出值和分类准确率\n",
    "            if batch_id == 0 and epoch_id==0:\n",
    "                # 打印模型参数和每层输出的尺寸\n",
    "                predicts, acc = model(images, labels, check_shape=True, check_content=False)\n",
    "            elif batch_id==401:\n",
    "                # 打印模型参数和每层输出的值\n",
    "                predicts, acc = model(images, labels, check_shape=False, check_content=True)\n",
    "            else:\n",
    "                predicts, acc = model(images, labels)\n",
    "            \n",
    "            #计算损失，取一个批次样本损失的平均值\n",
    "            loss = F.cross_entropy(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "            \n",
    "            #每训练了100批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 200 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}, acc is {}\".format(epoch_id, batch_id, avg_loss.numpy(), acc.numpy()))\n",
    "            \n",
    "            #后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "    #保存模型参数\n",
    "    paddle.save(model.state_dict(), 'mnist_test.pdparams')\n",
    "    \n",
    "#创建模型    \n",
    "model = MNIST()\n",
    "#启动训练过程\n",
    "train(model)\n",
    "\n",
    "print(\"Model has been saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8.3 加入校验或测试，更好评价模型效果 \n",
    "\n",
    "在训练过程中，我们会发现模型在训练样本集上的损失在不断减小。但这是否代表模型在未来的应用场景上依然有效？为了验证模型的有效性，通常将样本集合分成三份，训练集、校验集和测试集。\n",
    "\n",
    "- **训练集** ：用于训练模型的参数，即训练过程中主要完成的工作。\n",
    "- **验证集** ：用于对模型超参数的选择，比如网络结构的调整、正则化项权重的选择等。\n",
    "- **测试集** ：用于模拟模型在应用后的真实效果。因为测试集没有参与任何模型优化或参数训练的工作，所以它对模型来说是完全未知的样本。在不以校验数据优化网络结构或模型超参数时，校验数据和测试数据的效果是类似的，均更真实的反映模型效果。\n",
    "\n",
    "如下程序读取上一步训练保存的模型参数，读取校验数据集，并测试模型在校验数据集上的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start evaluation .......\r\n",
      "loss=0.06925583740963806, acc=0.9796974522292994\r\n"
     ]
    }
   ],
   "source": [
    "def evaluation(model):\n",
    "    print('start evaluation .......')\n",
    "    # 定义预测过程\n",
    "    params_file_path = 'mnist.pdparams'\n",
    "    # 加载模型参数\n",
    "    param_dict = paddle.load(params_file_path)\n",
    "    model.load_dict(param_dict)\n",
    "\n",
    "    model.eval()\n",
    "    eval_loader = test_loader\n",
    "\n",
    "    acc_set = []\n",
    "    avg_loss_set = []\n",
    "    for batch_id, data in enumerate(eval_loader()):\n",
    "        images, labels = data\n",
    "        images = paddle.to_tensor(images)\n",
    "        labels = paddle.to_tensor(labels)\n",
    "        predicts, acc = model(images, labels)\n",
    "        loss = F.cross_entropy(input=predicts, label=labels)\n",
    "        avg_loss = paddle.mean(loss)\n",
    "        acc_set.append(float(acc.numpy()))\n",
    "        avg_loss_set.append(float(avg_loss.numpy()))\n",
    "    \n",
    "    #计算多个batch的平均损失和准确率\n",
    "    acc_val_mean = np.array(acc_set).mean()\n",
    "    avg_loss_val_mean = np.array(avg_loss_set).mean()\n",
    "\n",
    "    print('loss={}, acc={}'.format(avg_loss_val_mean, acc_val_mean))\n",
    "\n",
    "model = MNIST()\n",
    "evaluation(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从测试的效果来看，模型在验证集上依然有98.6%的准确率，证明它是有预测效果的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8.4 加入正则化项，避免模型过拟合\n",
    "   \n",
    "### 2.8.4.1 过拟合现象\n",
    "\n",
    "对于样本量有限、但需要使用强大模型的复杂任务，模型很容易出现过拟合的表现，即在训练集上的损失小，在验证集或测试集上的损失较大，如 **图2** 所示。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/99b879c21113494a9d7315eeda74bc4c8fea07f984824a03bf8411e946c75f1b\" width=\"400\" hegiht=\"\" ></center>\n",
    "<center><br>图2：过拟合现象，训练误差不断降低，但测试误差先降后增</br></center>\n",
    "<br></br>\n",
    "\n",
    "反之，如果模型在训练集和测试集上均损失较大，则称为欠拟合。过拟合表示模型过于敏感，学习到了训练数据中的一些误差，而这些误差并不是真实的泛化规律（可推广到测试集上的规律）。欠拟合表示模型还不够强大，还没有很好的拟合已知的训练样本，更别提测试样本了。因为欠拟合情况容易观察和解决，只要训练loss不够好，就不断使用更强大的模型即可，因此实际中我们更需要处理好过拟合的问题。\n",
    "\n",
    "### 2.8.4.2 导致过拟合原因\n",
    "\n",
    "造成过拟合的原因是模型过于敏感，而训练数据量太少或其中的噪音太多。如**图3** 所示，理想的回归模型是一条坡度较缓的抛物线，欠拟合的模型只拟合出一条直线，显然没有捕捉到真实的规律，但过拟合的模型拟合出存在很多拐点的抛物线，显然是过于敏感，也没有正确表达真实规律。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/53c389bb3c824706bd2fbc05f83ab0c6dd6b5b2fdedb4150a17e16a1b64c243e\" width=\"700\" hegiht=\"\" ></center>\n",
    "<center><br>图3：回归模型的过拟合，理想和欠拟合状态的表现</br></center>\n",
    "<br></br>\n",
    "\n",
    "如**图4** 所示，理想的分类模型是一条半圆形的曲线，欠拟合用直线作为分类边界，显然没有捕捉到真实的边界，但过拟合的模型拟合出很扭曲的分类边界，虽然对所有的训练数据正确分类，但对一些较为个例的样本所做出的妥协，高概率不是真实的规律。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/b5a46f7e0fbe4f8686a71d9a2d330ed09f23bca565a44e0d941148729fd2f7d7\" width=\"700\" hegiht=\"\" ></center>\n",
    "<center><br>图4：分类模型的欠拟合，理想和过拟合状态的表现</br></center>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.4.3 过拟合的成因与防控\n",
    "\n",
    "为了更好的理解过拟合的成因，可以参考侦探定位罪犯的案例逻辑，如 **图5** 所示。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/34de60a675b64468a2c3fee0844a168d53e891eaacf643fd8c1c9ba8e3812bcc\" width=\"700\" hegiht=\"\" ></center>\n",
    "<center><br>图5：侦探定位罪犯与模型假设示意</br></center>\n",
    "<br></br>\n",
    "\n",
    "对于这个案例，假设侦探也会犯错，通过分析发现可能的原因：\n",
    "\n",
    "（1）情况1：罪犯证据存在错误，依据错误的证据寻找罪犯肯定是缘木求鱼。\n",
    "\n",
    "（2）情况2：搜索范围太大的同时证据太少，导致符合条件的候选（嫌疑人）太多，无法准确定位罪犯。\n",
    "\n",
    "那么侦探解决这个问题的方法有两种：或者缩小搜索范围（比如假设该案件只能是熟人作案），或者寻找更多的证据。归结到深度学习中，假设模型也会犯错，通过分析发现可能的原因：\n",
    "\n",
    "（1） 情况1：训练数据存在噪音，导致模型学到了噪音，而不是真实规律。\n",
    "\n",
    "（2）情况2：使用强大模型（表示空间大）的同时训练数据太少，导致在训练数据上表现良好的候选假设太多，锁定了一个“虚假正确”的假设。\n",
    "\n",
    "\n",
    "对于情况1，我们使用数据清洗和修正来解决。 对于情况2，我们或者限制模型表示能力，或者收集更多的训练数据。而清洗训练数据中的错误，或收集更多的训练数据往往是一句“正确的废话”，在任何时候我们都想获得更多更高质量的数据。在实际项目中，更快、更低成本可控制过拟合的方法，只有限制模型的表示能力。\n",
    "\n",
    "**（1）正则化项**\n",
    "\n",
    "为了防止模型过拟合，在没有扩充样本量的可能下，只能降低模型的复杂度，可以通过限制参数的数量或可能取值（参数值尽量小）实现。具体来说，在模型的优化目标（损失）中人为加入对参数规模的惩罚项。当参数越多或取值越大时，该惩罚项就越大。通过调整惩罚项的权重系数，可以使模型在“尽量减少训练损失”和“保持模型的泛化能力”之间取得平衡。泛化能力表示模型在没有见过的样本上依然有效。正则化项的存在，增加了模型在训练集上的损失。\n",
    "\n",
    "飞桨支持为所有参数加上统一的正则化项，也支持为特定的参数添加正则化项。前者的实现如下代码所示，仅在优化器中设置``weight_decay``参数即可实现。使用参数``coeff``调节正则化项的权重，权重越大时，对模型复杂度的惩罚越高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss is: [3.8228705], acc is [0.09375]\r\n",
      "epoch: 0, batch: 200, loss is: [0.07062767], acc is [0.953125]\r\n",
      "epoch: 0, batch: 400, loss is: [0.20030954], acc is [0.953125]\r\n",
      "epoch: 0, batch: 600, loss is: [0.09374876], acc is [0.96875]\r\n",
      "epoch: 0, batch: 800, loss is: [0.11705722], acc is [0.96875]\r\n",
      "epoch: 1, batch: 0, loss is: [0.03310085], acc is [0.984375]\r\n",
      "epoch: 1, batch: 200, loss is: [0.23823069], acc is [0.921875]\r\n",
      "epoch: 1, batch: 400, loss is: [0.16660276], acc is [0.953125]\r\n",
      "epoch: 1, batch: 600, loss is: [0.05889388], acc is [0.96875]\r\n",
      "epoch: 1, batch: 800, loss is: [0.02532948], acc is [0.984375]\r\n",
      "epoch: 2, batch: 0, loss is: [0.06577589], acc is [0.96875]\r\n",
      "epoch: 2, batch: 200, loss is: [0.08367997], acc is [0.984375]\r\n",
      "epoch: 2, batch: 400, loss is: [0.02483967], acc is [0.984375]\r\n",
      "epoch: 2, batch: 600, loss is: [0.07011881], acc is [0.984375]\r\n",
      "epoch: 2, batch: 800, loss is: [0.04859509], acc is [0.984375]\r\n",
      "epoch: 3, batch: 0, loss is: [0.048246], acc is [0.984375]\r\n",
      "epoch: 3, batch: 200, loss is: [0.10438204], acc is [0.953125]\r\n",
      "epoch: 3, batch: 400, loss is: [0.06529065], acc is [0.96875]\r\n",
      "epoch: 3, batch: 600, loss is: [0.06141832], acc is [0.984375]\r\n",
      "epoch: 3, batch: 800, loss is: [0.06838188], acc is [0.984375]\r\n",
      "epoch: 4, batch: 0, loss is: [0.06753349], acc is [0.96875]\r\n",
      "epoch: 4, batch: 200, loss is: [0.12629655], acc is [0.953125]\r\n",
      "epoch: 4, batch: 400, loss is: [0.03575302], acc is [0.984375]\r\n",
      "epoch: 4, batch: 600, loss is: [0.07168289], acc is [0.953125]\r\n",
      "epoch: 4, batch: 800, loss is: [0.00869386], acc is [1.]\r\n"
     ]
    }
   ],
   "source": [
    "def train(model):\n",
    "    model.train() \n",
    "\n",
    "    #各种优化算法均可以加入正则化项，避免过拟合，参数regularization_coeff调节正则化项的权重\n",
    "    opt = paddle.optimizer.Adam(learning_rate=0.01, weight_decay=paddle.regularizer.L2Decay(coeff=1e-5), parameters=model.parameters())           \n",
    "\n",
    "    EPOCH_NUM = 5\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #准备数据，变得更加简洁\n",
    "            images, labels = data\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.to_tensor(labels)\n",
    "            \n",
    "            #前向计算的过程，同时拿到模型输出值和分类准确率\n",
    "            predicts, acc = model(images, labels)\n",
    "            #计算损失，取一个批次样本损失的平均值\n",
    "            loss = F.cross_entropy(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "            \n",
    "            #每训练了100批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 200 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}, acc is {}\".format(epoch_id, batch_id, avg_loss.numpy(), acc.numpy()))\n",
    "            \n",
    "            #后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "    #保存模型参数\n",
    "    paddle.save(model.state_dict(), 'mnist_regul.pdparams')\n",
    "\n",
    "model = MNIST()\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start evaluation .......\r\n",
      "loss=0.07935721310694216, acc=0.9776074840764332\r\n"
     ]
    }
   ],
   "source": [
    "def evaluation(model):\n",
    "    print('start evaluation .......')\n",
    "    # 定义预测过程\n",
    "    params_file_path = 'mnist_regul.pdparams'\n",
    "    # 加载模型参数\n",
    "    param_dict = paddle.load(params_file_path)\n",
    "    model.load_dict(param_dict)\n",
    "\n",
    "    model.eval()\n",
    "    eval_loader = test_loader\n",
    "\n",
    "    acc_set = []\n",
    "    avg_loss_set = []\n",
    "    for batch_id, data in enumerate(eval_loader()):\n",
    "        images, labels = data\n",
    "        images = paddle.to_tensor(images)\n",
    "        labels = paddle.to_tensor(labels)\n",
    "        predicts, acc = model(images, labels)\n",
    "        loss = F.cross_entropy(input=predicts, label=labels)\n",
    "        avg_loss = paddle.mean(loss)\n",
    "        acc_set.append(float(acc.numpy()))\n",
    "        avg_loss_set.append(float(avg_loss.numpy()))\n",
    "    \n",
    "    #计算多个batch的平均损失和准确率\n",
    "    acc_val_mean = np.array(acc_set).mean()\n",
    "    avg_loss_val_mean = np.array(avg_loss_set).mean()\n",
    "\n",
    "    print('loss={}, acc={}'.format(avg_loss_val_mean, acc_val_mean))\n",
    "\n",
    "model = MNIST()\n",
    "evaluation(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**（2）暂退法Dropout**\n",
    "\n",
    "除了在优化目标中加入正则化项之外，神经网络模型也通常使用暂退法来改善过拟合问题。暂退法指在训练神经网络过程中随机丢掉一部分神经元来减少神经网络复杂度，它实现方法很简单：在每次迭代训练中，以一定概率随机屏蔽每一层中若干神经元，用余下神经元所构成网络来继续训练。\n",
    "\n",
    "**图6**是暂退法示意图，左边是完整的神经网络，右边是应用了暂退法之后的网络结构。应用暂退法之后，会将标了×的神经元从网络中删除，让它们不向后面的层传递信号。在学习过程中，丢弃哪些神经元是随机决定，因此模型不会过度依赖某些神经元，能一定程度上抑制过拟合。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/541fd4620951432292578ed77fc1f74bc1ce5559060345d084e20319414a7f07\" width=\"700\" hegiht=\"\" ></center>\n",
    "<center><br>图6：暂退法示意图</br></center>\n",
    "<br></br>\n",
    "\n",
    "通过飞桨[paddle.nn.functional.dropout](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/functional/dropout_cn.html#dropout) API可以实现Dropout操作。其输入是一个张量，即需要丢弃数据的神经元参数。该API的`axis`参数用于指定对输入张量进行Dropout操作的轴。默认为None，即对输入张量x中的任意元素，以丢弃概率p随机将一些元素输出置0。若参数`axis`不为None，则以一定的概率从图像特征或语音序列中丢弃掉整个通道。\n",
    "\n",
    "需要注意的是，在测试时，应用整个训练好的模型，不需要Dropout。所以存在训练和测试不一致的问题。通过`paddle.nn.functional.dropout` API的`mode`参数可以选择丢弃单元的方式，有两种`upscale_in_train`和`downscale_in_infer`，默认是`upscale_in_train`。计算方法如下:\n",
    "\n",
    "* upscale_in_train, 在训练时增大输出结果。\n",
    "\t* train: out = input * mask / ( 1.0 - p )\n",
    "\t* inference: out = input\n",
    "* downscale_in_infer, 在预测时减小输出结果\n",
    "\t* train: out = input * mask\n",
    "\t* inference: out = input * (1.0 - p)\n",
    "    \n",
    " 示例：\n",
    " ```\n",
    " 假定x是形状为2*3的2维张量:\n",
    "[[1 2 3]\n",
    " [4 5 6]]\n",
    "在对x做dropout时，程序会先生成一个和x相同形状的mask张量，mask中每个元素的值为0或1。\n",
    "每个元素的具体值，则是依据丢弃概率从伯努利分布中随机采样得到。\n",
    "比如，我们可能得到下面这样一个2*3的mask:\n",
    "[[0 1 0]\n",
    " [1 0 1]]\n",
    "将输入x和生成的mask点积，就得到了随机丢弃部分元素之后的结果:\n",
    "[[0 2 0]\n",
    " [4 0 6]]\n",
    "假定dropout的概率使用默认值，即 ``p=0.5`` ，若mode参数使用默认值，即 ``mode='upscale_in_train'`` ，\n",
    "则在训练阶段，最终增大后的结果为:\n",
    "[[0 4 0 ]\n",
    " [8 0 12]]\n",
    "在测试阶段，输出跟输入一致:\n",
    "[[1 2 3]\n",
    " [4 5 6]]\n",
    "若参数mode设置为'downscale_in_infer'，则训练阶段的输出为:\n",
    "[[0 2 0]\n",
    " [4 0 6]]\n",
    "在测试阶段，缩小后的输出为:\n",
    "[[0.5 1.  1.5]\n",
    " [2.  2.5 3. ]]\n",
    " ```\n",
    "\n",
    "下面我们在MINIST模型全连接层后面加入Dropout运算，查看模型训练和评估情况。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss is: [4.0833225], acc is [0.0625]\r\n",
      "epoch: 0, batch: 200, loss is: [0.07072611], acc is [1.]\r\n",
      "epoch: 0, batch: 400, loss is: [0.13994697], acc is [0.96875]\r\n",
      "epoch: 0, batch: 600, loss is: [0.10909003], acc is [0.953125]\r\n",
      "epoch: 0, batch: 800, loss is: [0.1880557], acc is [0.96875]\r\n",
      "epoch: 1, batch: 0, loss is: [0.22570458], acc is [0.9375]\r\n",
      "epoch: 1, batch: 200, loss is: [0.2441752], acc is [0.921875]\r\n",
      "epoch: 1, batch: 400, loss is: [0.0100032], acc is [1.]\r\n",
      "epoch: 1, batch: 600, loss is: [0.04133706], acc is [0.984375]\r\n",
      "epoch: 1, batch: 800, loss is: [0.09127815], acc is [0.953125]\r\n",
      "epoch: 2, batch: 0, loss is: [0.05260755], acc is [0.96875]\r\n",
      "epoch: 2, batch: 200, loss is: [0.13855451], acc is [0.953125]\r\n",
      "epoch: 2, batch: 400, loss is: [0.05476269], acc is [0.984375]\r\n",
      "epoch: 2, batch: 600, loss is: [0.30577427], acc is [0.921875]\r\n",
      "epoch: 2, batch: 800, loss is: [0.31517652], acc is [0.9375]\r\n",
      "epoch: 3, batch: 0, loss is: [0.06088963], acc is [0.984375]\r\n",
      "epoch: 3, batch: 200, loss is: [0.31231248], acc is [0.890625]\r\n",
      "epoch: 3, batch: 400, loss is: [0.06767518], acc is [0.953125]\r\n",
      "epoch: 3, batch: 600, loss is: [0.23350264], acc is [0.953125]\r\n",
      "epoch: 3, batch: 800, loss is: [0.09101789], acc is [0.9375]\r\n",
      "epoch: 4, batch: 0, loss is: [0.327186], acc is [0.9375]\r\n",
      "epoch: 4, batch: 200, loss is: [0.10689706], acc is [0.953125]\r\n",
      "epoch: 4, batch: 400, loss is: [0.0439705], acc is [0.96875]\r\n",
      "epoch: 4, batch: 600, loss is: [0.10556765], acc is [0.96875]\r\n",
      "epoch: 4, batch: 800, loss is: [0.04112688], acc is [0.984375]\r\n",
      "start evaluation .......\r\n",
      "loss=0.07983270236202011, acc=0.9721337579617835\r\n"
     ]
    }
   ],
   "source": [
    "import paddle.nn.functional as F\n",
    "# 定义模型结构\n",
    "class MNIST(paddle.nn.Layer):\n",
    "     def __init__(self):\n",
    "         super(MNIST, self).__init__()\n",
    "         \n",
    "         # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\n",
    "         self.conv1 = Conv2D(in_channels=1, out_channels=20, kernel_size=5, stride=1, padding=2)\n",
    "         # 定义池化层，池化核的大小kernel_size为2，池化步长为2\n",
    "         self.max_pool1 = MaxPool2D(kernel_size=2, stride=2)\n",
    "         # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\n",
    "         self.conv2 = Conv2D(in_channels=20, out_channels=20, kernel_size=5, stride=1, padding=2)\n",
    "         # 定义池化层，池化核的大小kernel_size为2，池化步长为2\n",
    "         self.max_pool2 = MaxPool2D(kernel_size=2, stride=2)\n",
    "         # 定义一层全连接层，输出维度是10\n",
    "         self.fc = Linear(in_features=980, out_features=10)\n",
    "     \n",
    "     #加入对每一层输入和输出的尺寸和数据内容的打印，根据check参数决策是否打印每层的参数和输出尺寸\n",
    "     # 卷积层激活函数使用Relu，全连接层激活函数使用softmax\n",
    "     def forward(self, inputs, label=None, check_shape=False, check_content=False, training=True):\n",
    "         # 给不同层的输出不同命名，方便调试\n",
    "         outputs1 = self.conv1(inputs)\n",
    "         outputs2 = F.relu(outputs1)\n",
    "         outputs3 = self.max_pool1(outputs2)\n",
    "         outputs4 = self.conv2(outputs3)\n",
    "         outputs5 = F.relu(outputs4)\n",
    "         outputs6 = self.max_pool2(outputs5)\n",
    "         outputs6 = paddle.reshape(outputs6, [outputs6.shape[0], -1])\n",
    "         outputs7 = self.fc(outputs6)\n",
    "\n",
    "         # 对FC层实施Dropout，指定第0维，丢弃概率为p\n",
    "         outputs = paddle.nn.functional.dropout(outputs7,p=0.01, axis=0,training=training)\n",
    "\n",
    "        # 如果label不是None，则计算分类精度并返回\n",
    "         if label is not None:\n",
    "             acc = paddle.metric.accuracy(input=F.softmax(outputs), label=label)\n",
    "             return outputs, acc\n",
    "         else:\n",
    "             return outputs\n",
    "\n",
    "def evaluation(model):\n",
    "    print('start evaluation .......')\n",
    "    # 定义预测过程\n",
    "    params_file_path = 'mnist_regul.pdparams'\n",
    "    # 加载模型参数\n",
    "    param_dict = paddle.load(params_file_path)\n",
    "    model.load_dict(param_dict)\n",
    "\n",
    "    model.eval()\n",
    "    eval_loader = test_loader\n",
    "\n",
    "    acc_set = []\n",
    "    avg_loss_set = []\n",
    "    for batch_id, data in enumerate(eval_loader()):\n",
    "        images, labels = data\n",
    "        images = paddle.to_tensor(images)\n",
    "        labels = paddle.to_tensor(labels)\n",
    "        predicts, acc = model(images, labels, training=False)\n",
    "        loss = F.cross_entropy(input=predicts, label=labels)\n",
    "        avg_loss = paddle.mean(loss)\n",
    "        acc_set.append(float(acc.numpy()))\n",
    "        avg_loss_set.append(float(avg_loss.numpy()))\n",
    "    \n",
    "    #计算多个batch的平均损失和准确率\n",
    "    acc_val_mean = np.array(acc_set).mean()\n",
    "    avg_loss_val_mean = np.array(avg_loss_set).mean()\n",
    "\n",
    "    print('loss={}, acc={}'.format(avg_loss_val_mean, acc_val_mean))\n",
    "\n",
    "model = MNIST()\n",
    "train(model)\n",
    "evaluation(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8.5 可视化分析\n",
    "\n",
    "训练模型时，经常需要观察模型的评价指标，分析模型的优化过程，以确保训练是有效的。之前的分析，我们往往使用打印Loss的方式，这比较起来并不够方便，也不够美观。将模型训练效果等数据可视化作图可选用两种工具：Matplotlib库和VisualDL。\n",
    "\n",
    "* Matplotlib库：Matplotlib库是Python中使用的最多的2D图形绘图库，它有一套完全仿照MATLAB的函数形式的绘图接口，使用轻量级的PLT库（Matplotlib）作图是非常简单的。\n",
    "\n",
    "* VisualDL：如果期望使用更加专业的作图工具，可以尝试VisualDL，飞桨可视化分析工具。VisualDL能够有效地展示飞桨在运行过程中的计算图、各种指标变化趋势和数据信息。\n",
    "\n",
    "### 2.8.5.1 使用Matplotlib库绘制损失随训练下降的曲线图\n",
    "\n",
    "将训练的批次编号作为X轴坐标，该批次的训练损失作为Y轴坐标。\n",
    "\n",
    "1. 训练开始前，声明两个列表变量存储对应的批次编号(iters=[])和训练损失(losses=[])。\n",
    "```\n",
    "iters=[]\n",
    "losses=[]\n",
    "for epoch_id in range(EPOCH_NUM):\n",
    "\t\"\"\"start to training\"\"\"\n",
    "```\n",
    "\n",
    "2. 随着训练的进行，将iter和losses两个列表填满。\n",
    "```\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "iters=[]\n",
    "losses=[]\n",
    "for epoch_id in range(EPOCH_NUM):\n",
    "\tfor batch_id, data in enumerate(train_loader()):\n",
    "        images, labels = data\n",
    "        predicts, acc = model(images, labels)\n",
    "        loss = F.cross_entropy(predicts, label = labels.astype('int64'))\n",
    "        avg_loss = paddle.mean(loss)\n",
    "        # 累计迭代次数和对应的loss\n",
    "   \titers.append(batch_id + epoch_id*len(list(train_loader()))\n",
    "\tlosses.append(avg_loss)\n",
    "```\n",
    "\n",
    "3. 训练结束后，将两份数据以参数形式导入PLT的横纵坐标。\n",
    "```\n",
    "plt.xlabel(\"iter\", fontsize=14)，plt.ylabel(\"loss\", fontsize=14)\n",
    "```\n",
    "4. 最后，调用plt.plot()函数即可完成作图。\n",
    "```\n",
    "plt.plot(iters, losses,color='red',label='train loss') \n",
    "```\n",
    "\n",
    "详细代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import MutableMapping\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import Iterable, Mapping\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import Sized\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss is: [3.1067178], acc is [0.125]\r\n",
      "epoch: 0, batch: 100, loss is: [0.25948155], acc is [0.921875]\r\n",
      "epoch: 0, batch: 200, loss is: [0.2500265], acc is [0.875]\r\n",
      "epoch: 0, batch: 300, loss is: [0.32702205], acc is [0.890625]\r\n",
      "epoch: 0, batch: 400, loss is: [0.08103482], acc is [0.96875]\r\n",
      "epoch: 0, batch: 500, loss is: [0.06687161], acc is [0.96875]\r\n",
      "epoch: 0, batch: 600, loss is: [0.18538702], acc is [0.96875]\r\n",
      "epoch: 0, batch: 700, loss is: [0.03654159], acc is [0.984375]\r\n",
      "epoch: 0, batch: 800, loss is: [0.08613557], acc is [0.953125]\r\n",
      "epoch: 0, batch: 900, loss is: [0.22812071], acc is [0.953125]\r\n",
      "epoch: 1, batch: 0, loss is: [0.07222291], acc is [0.984375]\r\n",
      "epoch: 1, batch: 100, loss is: [0.02553116], acc is [1.]\r\n",
      "epoch: 1, batch: 200, loss is: [0.0458651], acc is [0.984375]\r\n",
      "epoch: 1, batch: 300, loss is: [0.04750751], acc is [0.96875]\r\n",
      "epoch: 1, batch: 400, loss is: [0.13080978], acc is [0.9375]\r\n",
      "epoch: 1, batch: 500, loss is: [0.05986679], acc is [0.96875]\r\n",
      "epoch: 1, batch: 600, loss is: [0.09602988], acc is [0.96875]\r\n",
      "epoch: 1, batch: 700, loss is: [0.02209184], acc is [0.984375]\r\n",
      "epoch: 1, batch: 800, loss is: [0.12519023], acc is [0.953125]\r\n",
      "epoch: 1, batch: 900, loss is: [0.0548395], acc is [0.984375]\r\n",
      "epoch: 2, batch: 0, loss is: [0.01888405], acc is [0.984375]\r\n",
      "epoch: 2, batch: 100, loss is: [0.01061364], acc is [1.]\r\n",
      "epoch: 2, batch: 200, loss is: [0.01641076], acc is [1.]\r\n",
      "epoch: 2, batch: 300, loss is: [0.04714124], acc is [0.984375]\r\n",
      "epoch: 2, batch: 400, loss is: [0.03082629], acc is [0.984375]\r\n",
      "epoch: 2, batch: 500, loss is: [0.00466085], acc is [1.]\r\n",
      "epoch: 2, batch: 600, loss is: [0.03611708], acc is [0.984375]\r\n",
      "epoch: 2, batch: 700, loss is: [0.05530573], acc is [0.96875]\r\n",
      "epoch: 2, batch: 800, loss is: [0.00915828], acc is [1.]\r\n",
      "epoch: 2, batch: 900, loss is: [0.25927716], acc is [0.9375]\r\n",
      "epoch: 3, batch: 0, loss is: [0.0053554], acc is [1.]\r\n",
      "epoch: 3, batch: 100, loss is: [0.07718084], acc is [0.984375]\r\n",
      "epoch: 3, batch: 200, loss is: [0.00630295], acc is [1.]\r\n",
      "epoch: 3, batch: 300, loss is: [0.03986048], acc is [0.984375]\r\n",
      "epoch: 3, batch: 400, loss is: [0.02118919], acc is [0.984375]\r\n",
      "epoch: 3, batch: 500, loss is: [0.03682797], acc is [0.984375]\r\n",
      "epoch: 3, batch: 600, loss is: [0.03871151], acc is [0.984375]\r\n",
      "epoch: 3, batch: 700, loss is: [0.03735166], acc is [0.984375]\r\n",
      "epoch: 3, batch: 800, loss is: [0.05122434], acc is [0.984375]\r\n",
      "epoch: 3, batch: 900, loss is: [0.12567255], acc is [0.953125]\r\n",
      "epoch: 4, batch: 0, loss is: [0.04418489], acc is [0.984375]\r\n",
      "epoch: 4, batch: 100, loss is: [0.07105179], acc is [0.96875]\r\n",
      "epoch: 4, batch: 200, loss is: [0.04843749], acc is [1.]\r\n",
      "epoch: 4, batch: 300, loss is: [0.01279272], acc is [1.]\r\n",
      "epoch: 4, batch: 400, loss is: [0.06105454], acc is [0.96875]\r\n",
      "epoch: 4, batch: 500, loss is: [0.00378267], acc is [1.]\r\n",
      "epoch: 4, batch: 600, loss is: [0.10478292], acc is [0.984375]\r\n",
      "epoch: 4, batch: 700, loss is: [0.04497121], acc is [0.96875]\r\n",
      "epoch: 4, batch: 800, loss is: [0.03848124], acc is [0.984375]\r\n",
      "epoch: 4, batch: 900, loss is: [0.03699018], acc is [0.984375]\r\n",
      "epoch: 5, batch: 0, loss is: [0.08881403], acc is [0.96875]\r\n",
      "epoch: 5, batch: 100, loss is: [0.05881751], acc is [0.96875]\r\n",
      "epoch: 5, batch: 200, loss is: [0.21269678], acc is [0.96875]\r\n",
      "epoch: 5, batch: 300, loss is: [0.00178465], acc is [1.]\r\n",
      "epoch: 5, batch: 400, loss is: [0.0332341], acc is [0.984375]\r\n",
      "epoch: 5, batch: 500, loss is: [0.06160853], acc is [0.953125]\r\n",
      "epoch: 5, batch: 600, loss is: [0.14453772], acc is [0.96875]\r\n",
      "epoch: 5, batch: 700, loss is: [0.00417219], acc is [1.]\r\n",
      "epoch: 5, batch: 800, loss is: [0.04299318], acc is [0.984375]\r\n",
      "epoch: 5, batch: 900, loss is: [0.00138008], acc is [1.]\r\n",
      "epoch: 6, batch: 0, loss is: [0.04620922], acc is [0.984375]\r\n",
      "epoch: 6, batch: 100, loss is: [0.0113104], acc is [1.]\r\n",
      "epoch: 6, batch: 200, loss is: [0.00134751], acc is [1.]\r\n",
      "epoch: 6, batch: 300, loss is: [0.08195499], acc is [0.96875]\r\n",
      "epoch: 6, batch: 400, loss is: [0.03043568], acc is [0.984375]\r\n",
      "epoch: 6, batch: 500, loss is: [0.0022357], acc is [1.]\r\n",
      "epoch: 6, batch: 600, loss is: [0.01159343], acc is [1.]\r\n",
      "epoch: 6, batch: 700, loss is: [0.01395741], acc is [1.]\r\n",
      "epoch: 6, batch: 800, loss is: [0.00451766], acc is [1.]\r\n",
      "epoch: 6, batch: 900, loss is: [0.05307096], acc is [0.984375]\r\n",
      "epoch: 7, batch: 0, loss is: [0.04470662], acc is [0.984375]\r\n",
      "epoch: 7, batch: 100, loss is: [0.06655695], acc is [0.96875]\r\n",
      "epoch: 7, batch: 200, loss is: [0.14185987], acc is [0.953125]\r\n",
      "epoch: 7, batch: 300, loss is: [0.00670908], acc is [1.]\r\n",
      "epoch: 7, batch: 400, loss is: [0.05755713], acc is [0.96875]\r\n",
      "epoch: 7, batch: 500, loss is: [0.07407703], acc is [0.96875]\r\n",
      "epoch: 7, batch: 600, loss is: [0.02188261], acc is [0.984375]\r\n",
      "epoch: 7, batch: 700, loss is: [0.03728414], acc is [0.984375]\r\n",
      "epoch: 7, batch: 800, loss is: [0.002194], acc is [1.]\r\n",
      "epoch: 7, batch: 900, loss is: [0.00173302], acc is [1.]\r\n",
      "epoch: 8, batch: 0, loss is: [0.03637866], acc is [0.984375]\r\n",
      "epoch: 8, batch: 100, loss is: [0.03711292], acc is [0.984375]\r\n",
      "epoch: 8, batch: 200, loss is: [0.05949993], acc is [0.96875]\r\n",
      "epoch: 8, batch: 300, loss is: [0.03926613], acc is [0.984375]\r\n",
      "epoch: 8, batch: 400, loss is: [0.00787284], acc is [1.]\r\n",
      "epoch: 8, batch: 500, loss is: [0.03721984], acc is [0.984375]\r\n",
      "epoch: 8, batch: 600, loss is: [0.00696141], acc is [1.]\r\n",
      "epoch: 8, batch: 700, loss is: [0.04140003], acc is [1.]\r\n",
      "epoch: 8, batch: 800, loss is: [0.00694878], acc is [1.]\r\n",
      "epoch: 8, batch: 900, loss is: [0.11778253], acc is [0.953125]\r\n",
      "epoch: 9, batch: 0, loss is: [0.05109105], acc is [0.984375]\r\n",
      "epoch: 9, batch: 100, loss is: [0.04488494], acc is [0.984375]\r\n",
      "epoch: 9, batch: 200, loss is: [0.0014867], acc is [1.]\r\n",
      "epoch: 9, batch: 300, loss is: [0.0414663], acc is [0.984375]\r\n",
      "epoch: 9, batch: 400, loss is: [0.03694858], acc is [0.984375]\r\n",
      "epoch: 9, batch: 500, loss is: [0.1676015], acc is [0.921875]\r\n",
      "epoch: 9, batch: 600, loss is: [0.07532958], acc is [1.]\r\n",
      "epoch: 9, batch: 700, loss is: [0.03605957], acc is [0.984375]\r\n",
      "epoch: 9, batch: 800, loss is: [0.00361382], acc is [1.]\r\n",
      "epoch: 9, batch: 900, loss is: [0.07275441], acc is [0.96875]\r\n"
     ]
    }
   ],
   "source": [
    "#引入matplotlib库\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(model):\n",
    "    model.train()\n",
    "    \n",
    "    opt = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\n",
    "    \n",
    "    EPOCH_NUM = 10\n",
    "    iter=0\n",
    "    iters=[]\n",
    "    losses=[]\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #准备数据，变得更加简洁\n",
    "            images, labels = data\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.to_tensor(labels)\n",
    "            \n",
    "            #前向计算的过程，同时拿到模型输出值和分类准确率\n",
    "            predicts, acc = model(images, labels)\n",
    "            #计算损失，取一个批次样本损失的平均值\n",
    "            loss = F.cross_entropy(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "            \n",
    "            #每训练了100批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 100 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}, acc is {}\".format(epoch_id, batch_id, avg_loss.numpy(), acc.numpy()))\n",
    "                iters.append(iter)\n",
    "                losses.append(avg_loss.numpy())\n",
    "                iter = iter + 100\n",
    "            \n",
    "            #后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "            \n",
    "    #保存模型参数\n",
    "    paddle.save(model.state_dict(), 'mnist.pdparams')\n",
    "    \n",
    "    return iters, losses\n",
    "    \n",
    "model = MNIST()\n",
    "iters, losses = train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:2349: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  if isinstance(obj, collections.Iterator):\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:2366: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  return list(data) if isinstance(data, collections.MappingView) else data\r\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEjCAYAAADHWv01AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XmcFPWd//HXB4ZBLrkZEBHwSjQmK0dUwmrwiFe8NRvz88KYRU00XtlddT2SmE3MriFZQzbIRjxINBglBBXjmsggMYByqYAQBgNyyCEoMNzDfH5/fKvtpqerZ6ZnpnuGfj8fj350V9W3qr7fqu761PdT1d3m7oiIiGTSqtAVEBGR5ktBQkREYilIiIhILAUJERGJpSAhIiKxFCRERCSWgoRIGjN73MzczL6bx3WOiNa5Il/rFKmLkkJXQCTBzEYCA4DJ7r6gsLUREVCQkOZlJPBFYAVQyCDxAbAU+LCAdRBpFhQkRNK4+13AXYWuh0hzoGsSIiISS0FCCs7MRpqZE1JNAI9FF3E9/WJuoqyZlUfDV5jZdDPbFI2/KBrf2szOMbNHzGyuma03sz1mttbMfm9mp2WpT8YL12Y2IFGnaPg4M/utma0zs11mtsTM7jWz0kbdQMn1n2pmk6L17Ymea2tLp6hOc81sW8o2mGNm/2Vmx2WY54tm9qyZrY7KbzGzZWY22cyuNzMdN4qI0k3SHOwE1gPdgDbA1mhcwsZMM5nZw8DNQDWwJXpOOAaYmjK8FdgD9AEuAi4ys7vd/Ue5VNjMzgQmA+2idbcBPgV8HxgSraPRmNkPgH+PBj1aZy+SbXkwSpOlztMZ+CtwbDQqsZ3KCNthCLAPuDNlnlHAIymL2QG0Bo6MHhcCTwC7GrF50ozpjEAKzt0nuntvwgEN4BZ3753y+HyG2YYANwH3A93dvRvQNWUZe4DxwFlAZ3fv7O4dCQfIewkHx/8wsxNzrPZE4HlgoLt3AQ4mXMdw4EIzOzfH5dZgZpeTDBBjgF7u3hXoCfw8Gn+nmV2ZNusthACxETgPaBttp4OAownBYXnKetoDP4kGxwOHuXuHaLt1B84Bnmb/YCwHOnfXQ49m8QDKCQfZkVnKjIzKOPDDBqzr3mgZj2WY9ng07btp4wekrPv/AMsw7/PR9PH1rM+IaL4VaeMNWBZNezpm3qei6X8HWqWMnxqN/7c61uGEqHwl0LrQ7wc9msdDPQlpqfYBoxsw//PR8/Ac53/Q3TP9Gcvk6LlGrj9HxxPSPAA/iCnzveh5AOFAn7A1eu5Tx3Ulyrch9BxEFCSkxapw96zfYzCzdmZ2m5mVm9kGM9ubcuF5flTskBzX/2bM+DXRc9ccl5tucPS80d0XZSrg7ktT1js4ZVLimsy3zWxCdCG/U5Z1LYsepcDMaNt92sysAfWXFk5BQlqqjBezE8ysD+ELeaMJd031BHZH860n+UW5Drms3N23xUxKXNBtk8tyM+gZPa/JWgpWp5XH3Z8ExhFSVlcSgsbHZjbfzL4fbSNSyu8D/l+0rsMJ2+5d4EMz+52ZXaCAUXwUJKSl2lfL9J8RLs6+B1wKdHP3ju7ey8NF8pOauoKN7KBcZnL36wmpr+8TrvnsJqSw7gWWmdmX0srPAY4iBJUnCduvG3AZ8AfgRTNrnVsTpCVSkJADTvQ9hQujwSvcfZK7f5RWrCzP1cpVosfUr5Zyh6aV/4S7L3L3+939VKALcD7wDqEX9YSZtUkrv9Pdf+Pu17j7EYRexY8IF7XPAW7IuTXS4ihISHOSuLWyoSmNHkDb6PX8mDJnNHAd+TIveu5gZidkKmBmRwN908pn5O573P0F4CvRqD6EnkO2ef7u7ncTbvuF5JcepQgoSEhzkri7pksDl7ONcNYL8Nn0iVEu/uYGriNfFgAV0eu7Y8p8N3peAbyRGFnLN79Tv6zYtg7lU+dpm7WUHFAUJKQ5Sdy9c0n0beGcRBeVZ0WD483seAAza2VmpwPTaXhvJS+i22zviQYvNLOfm1l3ADPrHn3r/GvR9HvcPfWLbn8ys4fN7BQza5cYaWafIXwXBMIv3r4TvT7XzGaa2T+bWf+U8u3N7J+BK6JRLzdmG6V5089ySHMyAfgO8I+EO2o2AHuB1e7+j/Vc1m3ANEJPYr6ZbSecFLUDNgNfJ/mdhmbN3Sea2WcJ37q+CfimmW0BOpM80XvQ3X+TNuvBhB7TzUB1NE87khfBdwBXuXtVyjwnRQ/MbCfhbq0uJIPqVMIdU1Ik1JOQZsPdlwBfAv5I+I2h3kB/khdl67Os2cAwQiD4iHBL6gbC7xIdD7zVOLXOD3e/BzidcIfRh0BHYBMwBTjD0363KfINws+WTAPeJwQIgCWEn/c4zt3/nFL+VeAqwm8zvUMIIp2i9bwCXA2cnxZU5ABnmb80KiIiop6EiIhkoSAhIiKxFCRERCSWgoSIiMRq8bfA9ujRwwcMGJDTvNu3b6dDh5x+361FK8Z2F2OboTjbXYxthvq3e+7cuR+6e8/ayrX4IDFgwADmzJmT07zl5eWMGDGicSvUAhRju4uxzVCc7S7GNkP9221mK+tSTukmERGJpSAhIiKxFCRERCSWgoSIiMRSkBARkVgKEiIiEktBQkREYhVvkFi4kAHjx8OGDYWuiYhIs1W8QWLJEgZMmKAgISKSRfEGiZLoy+ZV+v8UEZE4ChJ79xa2HiIizVjxBok2bcKzehIiIrHyFiTM7CAze8PM3jKzRWb2vQxl2prZRDOrMLPZZjagySqkdJOISK3y2ZPYDZzm7v9A+CP6s83spLQy1wEfufuRwE+BHzdZbZRuEhGpVd6ChAeV0WCb6OFpxS4EnohePwucbmbWJBVSuklEpFZ5/T8JM2sNzAWOBH7h7rPTivQFVgG4e5WZbQG6Ax+mLWcUMAqgrKyM8vLyetel07vvMgR4e948NpeW1nv+lqyysjKnbdaSFWOboTjbXYxthqZrd16DhLvvA443sy7A783sOHdfmMNyxgHjAIYOHeo5/cHIwQcD8LljjoEi+4OSYvxTlmJsMxRnu4uxzdB07S7I3U3u/jEwDTg7bdIaoB+AmZUAnYFNTVIJpZtERGqVz7ubekY9CMysHfAlYElasSnANdHry4BX3T39ukXj0N1NIiK1yme6qQ/wRHRdohXwjLu/YGbfB+a4+xTgUWCCmVUAm4HLm6w2urtJRKRWeQsS7v42MCjD+PtSXu8CvpKXCindJCJSq+L9xrXSTSIitVKQULpJRCRW8QYJpZtERGpVvEFCPQkRkVopSKgnISISq3iDhNJNIiK1Kt4goXSTiEitijdItGqFm6knISKSRfEGCcBLShQkRESyKO4g0bq10k0iIlkoSKgnISISS0FCQUJEJJaChNJNIiKxijpIVOvCtYhIVkUdJJRuEhHJTkFC6SYRkVjFHSSUbhIRyaq4g4TSTSIiWSlIKN0kIhJLQUI9CRGRWAoSChIiIrEUJJRuEhGJVdxBQnc3iYhklbcgYWb9zGyamS02s0VmdkuGMiPMbIuZLYge9zVlnZRuEhHJriSP66oC7nD3eWbWCZhrZq+4++K0cjPc/bx8VMhbt4Y9e/KxKhGRFilvPQl3/8Dd50WvtwHvAn3ztf5M9NtNIiLZ5bMn8QkzGwAMAmZnmDzMzN4C1gLfcfdFGeYfBYwCKCsro7y8PKd6HO3O9i1beDPH+VuqysrKnLdZS1WMbYbibHcxthmasN3untcH0BGYC1ySYdrBQMfo9bnAstqWN2TIEM/VutNOcz/qqJznb6mmTZtW6CrkXTG22b04212MbXavf7uBOV6HY3Ze724yszbAc8Bv3H1S+nR33+ruldHrqUAbM+vRVPXRhWsRkezyeXeTAY8C77r76JgyvaNymNkJUf02NVWdFCRERLLL5zWJ4cBVwDtmtiAadzdwGIC7jwUuA240sypgJ3B51C1qEvoynYhIdnkLEu7+F8BqKTMGGJOfGunLdCIitSnub1wr3SQikpWChNJNIiKxijtIKN0kIpJVcQcJpZtERLJSkNi3D5ruBioRkRatqINEdUl0c5d6EyIiGRV1kPDWrcMLBQkRkYwUJEB3OImIxFCQAPUkRERiKEiAgoSISAwFCVC6SUQkRnEHCd3dJCKSVXEHCaWbRESyUpAApZtERGIUd5BQuklEJKviDhJKN4mIZKUgAUo3iYjEKOogUa2ehIhIVkUdJJRuEhHJTkEClG4SEYlR3EFCdzeJiGRV3EFC6SYRkawUJEDpJhGRGHkLEmbWz8ymmdliM1tkZrdkKGNm9rCZVZjZ22Y2uCnrpHSTiEh2JXlcVxVwh7vPM7NOwFwze8XdF6eUOQc4KnqcCPwyem4SSjeJiGSXt56Eu3/g7vOi19uAd4G+acUuBJ70YBbQxcz6NFmdEj0JpZtERDLKZ0/iE2Y2ABgEzE6b1BdYlTK8Ohr3Qdr8o4BRAGVlZZSXl+dUj327dgGwZOFC1uW4jJaosrIy523WUhVjm6E4212MbYama3feg4SZdQSeA2519625LMPdxwHjAIYOHeojRozIqS4zN24E4NNHHsmnc1xGS1ReXk6u26ylKsY2Q3G2uxjbDE3X7rze3WRmbQgB4jfuPilDkTVAv5ThQ6NxTaJadzeJiGSVz7ubDHgUeNfdR8cUmwJcHd3ldBKwxd0/iCnbYLpwLSKSXT7TTcOBq4B3zGxBNO5u4DAAdx8LTAXOBSqAHcC1TVkhfU9CRCS7vAUJd/8LYLWUceBb+amRvichIlIbfeMaFCRERGIoSIDSTSIiMYo6SNCqVXioJyEiklFxBwmAkhIFCRGRGAoSJSVKN4mIxFCQaNNGPQkRkRgKEko3iYjEUpBQuklEJJaChNJNIiKxFCSUbhIRiaUgoXSTiEgsBQmlm0REYilIKN0kIhKrXkHCzHqaWc+U4c+a2Q/M7GuNX7U8UbpJRCRWfXsSzwDnA5hZD+A14GJgrJnd0ch1yw+lm0REYtU3SHwOmBW9vgyocPfPAFcD1zdmxfJG6SYRkVj1DRLtgMro9RmEvxsFmMf+/03dcijdJCISq75BYhlwiZn1A84E/i8aXwZ83JgVyxulm0REYtU3SHwP+DGwApjl7rOj8WcB8xuxXvmjdJOISKx6/ce1u08ys8OAQ4C3Uib9CXiuMSuWN0o3iYjEqleQAHD39cD6xLCZHQm85e67GrNieaN0k4hIrPp+T+KHZnZN9NrM7BXgb8AHZnZiU1SwySndJCISq77XJK4AlkavzwGOB04CngQezDajmY03sw1mtjBm+ggz22JmC6LHffWsW26UbhIRiVXfdFMZsDp6fS7wjLu/YWabgTm1zPs4MIYQUOLMcPfz6lmnhlG6SUQkVn17EpuA/tHrM4E/R69LAMs2o7u/Bmyu5/qantJNIiKx6hskngOeiq5FdANejsYfD1Q0Qn2GmdlbZvaSmX2mEZZXO6WbRERi1TfddDuwEjgM+Fd33x6N7wP8soF1mQf0d/dKMzsXmAwclamgmY0CRgGUlZVRXl6e0worKytZs2EDPXfu5K85LqMlqqyszHmbtVTF2GYoznYXY5uhCdvt7nl7AAOAhXUsuwLoUVu5IUOGeK6mTZvm/u1vu3fpkvMyWqJp06YVugp5V4xtdi/Odhdjm93r325gjtfhWFzv70mYWRnwLeBYwIHFwC/cfUNDgpWZ9QbWu7ub2QmEVNimhiyzTpRuEhGJVa8gYWbDgT8Svkw3Mxp9BXCbmZ3l7jOzzPs0MALoYWargfuBNgDuPpbwq7I3mlkVsBO4PIp2TUt3N4mIxKpvT+Ih4GngBnevBjCzVsBY4CfAF+JmdPesf0zk7mMIt8jml+5uEhGJVd8gcTwwMhEgANy92sxG05J/4G/fPnAHy3oXr4hI0anvLbBbgIEZxg+kJf9UOKg3ISKSQX2DxG+BR83sCjMbGD2uBH5FSEO1PCVRZ0pBQkSkhvqmm/6V8M3q8SS/Zb2H8B2JOxu3anmSCBJ790K7doWti4hIM1Pf/5PYA9xiZncBR0Sjl7v7jkavWb4o3SQiEqvWIGFmU+pQBgB3v6AR6pRfSjeJiMSqS0+i6b/QVkiJnoS+UCciUkOtQcLdr81HRQpGPQkRkVj1vbvpwKMgISISS0FC6SYRkVgKEupJiIjEUpBQkBARiaUgoXSTiEgsBQn1JEREYilIKEiIiMRSkFC6SUQkloKEehIiIrEUJBQkRERiKUgo3SQiEktBQj0JEZFYChIKEiIisRQklG4SEYmlIKGehIhIrLwFCTMbb2YbzGxhzHQzs4fNrMLM3jazwXmpmIKEiEisfPYkHgfOzjL9HOCo6DEK+GUe6qR0k4hIFnkLEu7+GrA5S5ELgSc9mAV0MbM+TV4x9SRERGLV5T+u86UvsCpleHU07oP0gmY2itDboKysjPLy8pxWWFlZyYyZMzkZqFiyhNU5LqelqayszHmbtVTF2GYoznYXY5uh6drdnIJEnbn7OGAcwNChQ33EiBE5Lae8vJyTTzgBgCP79+fIHJfT0pSXl5PrNmupirHNUJztLsY2Q9O1uznd3bQG6JcyfGg0rmkp3SQiEqs5BYkpwNXRXU4nAVvcvUaqqdElgoQuXIuI1JC3dJOZPQ2MAHqY2WrgfqANgLuPBaYC5wIVwA7g2rxUrFWr8FBPQkSkhrwFCXf/Wi3THfhWnqqzv5ISBQkRkQyaU7qpcEpKlG4SEclAQQLCF+rUkxARqUFBApRuEhGJoSABSjeJiMRQkAClm0REYihIgNJNIiIxFCRA6SYRkRgKEqB0k4hIDAUJULpJRCSGggQo3SQiEkNBApRuEhGJoSABSjeJiMRQkAClm0REYihIgNJNIiIxFCRA6SYRkRgKEqB0k4hIDAUJULpJRCSGggQo3SQiEkNBAkJPQukmEZEaFCRAPQkRkRgKEqAgISISQ0EClG4SEYmhIAHqSYiIxMhrkDCzs81sqZlVmNmdGaaPNLONZrYgenwjLxVTkBARyagkXysys9bAL4AvAauBN81sirsvTis60d1vyle9AKWbRERi5LMncQJQ4e7vufse4LfAhXlcfzz1JEREMspbTwLoC6xKGV4NnJih3KVmdgrwN+A2d1+VXsDMRgGjAMrKyigvL8+pQpWVlZSXlzNwzRoO27uX6Tkup6VJtLuYFGOboTjbXYxthqZrdz6DRF08Dzzt7rvN7HrgCeC09ELuPg4YBzB06FAfMWJETisrLy9nxIgRMH06VFcz4otfBLOcK99SfNLuIlKMbYbibHcxthmart35TDetAfqlDB8ajfuEu29y993R4K+AIXmpWUkUK5VyEhHZTz6DxJvAUWY20MxKgcuBKakFzKxPyuAFwLt5qZmChIhIRnlLN7l7lZndBLwMtAbGu/siM/s+MMfdpwDfNrMLgCpgMzAyL5Vr0yY8790L7drlZZUiIi1BXq9JuPtUYGrauPtSXt8F3JXPOgHqSYiIxNA3rkFBQkQkhoIE7J9uEhGRTyhIgHoSIiIxFCRAQUJEJIaCBMSnm6qqYPRoWLcu/3USEWkGFCQgvifx8MNwxx3w+ON5r5KISHOgIAGZg8TKlXDvveH1vHn5r5OISDOgIAE1003ucFP0a+UnnaQgISJFS0ECkj2Jjz8Oz5MmwQsvwAMPwPnnw/LlyWlSPxUVIeiKSIukIAHQpUt4PvNMOPRQ+MY3YNAg+Pa3YUj0G4Pz5xeufi3V4sVw1FHw/POFromI5EhBAuCEE+Avf4Gf/ARGjIBPfQoefTT0MAYNCmUamnL66CNYu7bBVW1RZs0KzzNnFrYeIpKz5vZ/EoVhBsOHh0e6Xr1C76KhQeKaa8KZ9bJlRfGfFUBym6kXVtPu3bBiRTghEWnG1JOoiyFDGhYkNm2Cl14K1zbeeqvx6tXcJYLD/Pm6LpHuRz+Cz30ONm8udE1EslKQqIvBg2HpUqiszDz9ueeyny1PmpS8vXby5MavX3O0bx8sWAAdO8KGDfDBB4WuUfPy7LOwZ08yJSfSTClI1MXgweFMeMGCmtPWrYPLL4fbbouff+LEcAF3+HD4wx+arp7NybJlsGMHfPWrYTjTtitWy5bBokXh9euvF7Yu0jxUVe1/MtmMKEjUxeDB4TlTymn8+LBjZ8wIZ8zp1q+HadPCwfKii8LBcuXKpq1vc5DYVtdeG551XSIp0Zvs109BQoIJE+DSS+GRRwpdkxoUJOrikEOgd++aQWLfvrBTDz8cqqszp5Keey5M++pX4cILw7gpU2qWq82+ffWfp5Dmz4e2bcOdY0ccoSCRavLkcNfcJZfAG2/U7Sfqly+HT38aZs9u+vo1laoquO46ePnlQtek+XniifD8wAOwfXth65JGQaKuBg+uGST++Ed4/3148EE48sgQENJNnAjHHgvHHRdSTsccU//rEi+9BD17Qnl53cq7w913h9t6C2XePPjsZ8O32QcNyn+66c034cYbYdeu/K63NuvWhVuCL744pB937qzbtrnttnBdbNy4pq9jUxk9OvS8/+M/Cl2TxrNtG2zZ0rBlrFgB06fDeeeFzMOYMY1StcaiIFFXgweHW1h37kyOGzs29DAuuih0FV99df+7VdauDWmoRF4eQm9i+vTwvYm62L0bbr45lB85ErZurX2eqVPD3TOXXgobN9ZtPY3JPfQcEt8xGTQonAk39MNUVzt2hOtEY8fCQw817rLfeAPWrMl9/ilTwva56CL4whfCuNpSTi+/HL6Q2K1bOBHZvTv39RdKRQXcfz906hQ+EwdKyvXcc8MJ4KZNuS9jwoTwPGZMWN6Pf9ysfuFBQaKuhgwJKZ+33w7DK1fCiy+G7nObNuGAXFW1fyrpd78LB4TUIHHRRWE5U6dSJz/7WTjAPvAArFoVfpU2YcYMOOWUmgeZBx+EsrLwRrvhhvzffrpyZQhqiWs5xx8fnvN1++9998F774X1//CHjXdAWrMGTj45POp6UFixIlyTSpg8OaTfjjsO+vaF/v3hr3+Nn3/vXrj11tBTffTREGhbWrrGHUaNgtLS0PsGeOqpwtapMcyaFXrrq1eHX2nI5XPmDk8+CaeeGt4LP/hB+Oz85CeNX99cuXuLfgwZMsRzNW3atLoXXrnSHdyHDXMfM8b9xhvdW7UK493dq6vdDzvM/bzzwvDy5e59+7oPGrT/cvbtc+/Tx/0rX6l9nWvXunfs6H7hhWH4zjtDHZ5/3v2HP3Rv3ToMH364e2VlKDNjRhj38MPuP/5xeD1hQu7tzsWkSWG9s2Yl2wHuP/tZGK6qcv/ud90XLGj8dc+eHfbLDTeEfdOunfullybbvHev+9tvhzrU1+23h21eWup++ulhWdksX+7eu3do+wUXuL/zTpj3jjuSZb72NfdDDgnvn0xGj07u8z173Lt3D/PUUa37+s473U891f2jj+q8zHp79NHQhrFjw/Dw4e7HHpu5zZWV7r/7nfvrr+e8uiZ/fydcfrl7587hvQzuv/xl/Zfx+uth3scfT477p39y79DB/f33s8/72GPuq1Z9MljfdgNzvA7H2IIf5Bv6yFuQqK52v+8+9yOPDJsNkgEh4dZbw0HgnXfc+/d379bN/a23ai7rppvCgezXv86+zquvDstbtiwM79rl/tnPhnnB/atfDQcPcL/ttlDmvPPCgaSyMhwIhw8Pb+SUN1yjf4h27nSfNy/5ob/nnlDH7duTZcrK3EeODK//8z+TwW3btsarx+7d7scd537ooe5btoRxP/iBO/iChx5yf/HFcHCCsB8feSTUPd2OHe733hv2Y8LGje7t27tfdZX7+PFhGbffHl+XNWvcBw4M74G77w7zmoX5ZsxIlhszJoz7+99rLuONN8K+O/vs5La9/vqwrMRJQS2y7uvZs5N1Gj58//2Vi61b9w++a9eGtnfo4H7yyeEEyT0cTMF9/vxk2ddeC+/n9u3DtLZt3XN8n2Zs85Il4X03b15Oy6xh1apwwnD77aFdZ53lftBB+79n6mLUqNDmrVuT45YuDdusT5/kiVa6114L++7mmz8ZpSBR6CCRaulS9//5n3CmmCpxFt++ffhwz52bef5t28LZm5n7r34VxlVWuo8b537ppe7nnOM+YkRY1r/92/7zLljgfswx4awsceC48cawrP/93zDP976XLF9REd5wAweGg05t7d69O/RSrrzS/Zlnsh84Fi50v+UW965dk3Wtrnb/8pfdP/OZ/cuedZb7P/yD+6JF4QDw+c+HOt9ww/7lVqxwX706c73efz982OfNc3/zzdAjWLrU/dVX3b/zHfdPfzrU44UXkvPt3Ol+xBFeVVqaDA4PPeQ+dGgY7t3bffLkZPkdO9zPPDNMO+SQZF3uvTeMW7QoDN98cxi+/vpw0Hv55bBvlixxX7w4tL9jx3Agdg9B4IIL3IcM2f9AOn9+WM5vfpMct369+3XXhe3Tu7f73/6WnDZtWig/cWIY3rfP/ckna74Xq6rc77vPl9x+e+Yz9qqqsA169w5n+q1ahX20e3fNsnUxblw4aB50kPvgweFkpbQ0tOGSS5I9bnf3Dz90LylJ9qheeCEM9+gR3g9Tp4Zg3qmT+5w5yfn27AmPWrz24ovuGzaEIDVjhvvFFyeDIbh/4QvuTz2VuSe4bVvm7TVzZvJkzd39rrvCNnvvvTC8bp17r16h/cceGz4DDz5Ys8e6ebP700+7v/RSeA937hxOPNK9/Xb4zJaW7t/LcA8nQP371zjJOiCCBHA2sBSoAO7MML0tMDGaPhsYUNsyCxIk4iRSSZ06xZ8BJOzYET6UEFJPXbqE1wMGhA/vySeHnkTqGUacLVvc+/UL83foED6EqWbODKmwNm3cR4/2aa++mnk5r7+ePNNO1Cdx9lxRkSy3caP7FVeE6W3ahDPAq64KwzfdFLbBlVfuv+w77wwHgiFDwsFg/fpwYAf3P/4xfPjvvz8caFq1CoHy2WdD6uqKK9wPPjj5Ic/0aNMmpIAee6xmu155xbf36+f+3/+dPAhWV7v/+c/hgAbhoP/RRyFAmIWg0LFjmP7BB2F7XHxxcpl79oT91rZt5vqUlobl12bv3rCeb34zvH/Gjg0HjjZt3P/lX5I9ooSqqrB9L77Y/eOPw8EIQo/34L4xAAAMWUlEQVQl0UPZtSucbCTqcsEFYZ+leuSR/YNTIiV0/vmhvfWRODk5/fRw4D/zTPcjjghtSj2wpjr//BCE//SnsA2HDAntSVi9OhwIe/QIPbcrrwzbpWvX8J7IZNs292uvrbkvunYNvdulS0P6LpEN+Pznw8HYPZxMfPe7oS7DhiV7BDt3Jk8I2rULJwTbt4ftnfp+cA8nCbfd5n7RRaHHDyFAJnqrixfvn4lIPF55JXN7PvzQ/bTTQplrr01un5Ejw2fkr3/dr3iLDxJAa2A5cDhQCrwFHJtW5pvA2Oj15cDE2pbbrIKEe/Lsti527Qof4JKScKCdMSM+N12bl17y/dJO6TZtCusC31lWFl7ffXfodXz968mezWGHhTO7qqpwkEt0h0tKQgB47DH3nj3DQeyee8IZm3uo9x13JN/4o0fvv/6JE5PTnnkmjNu5MwSlvn3dTzghTLvyyrDcvn2T5bt3D3UcNy6cAU6e7D5lSshd//rXIeVWSzCN3de7doU0YSLAmoWDknvYDq1aJa8rvPlmzfn37Quph/LycPB66qkwf33SGmecEQ4eX/xi8mC7ZEl8+VtuCQezo48O++WBB8Lr0tJwsD/jjE/2wd9uuimMP+SQcDBfuDAE6G7dwvpS328//3nYr506hd7Wrl3hvfz00+EAescd4f1w3XXuP/2p+/TpydTR2WdnTt3FSbwfSkpCryv9xMY99KB69UoGwWuvTfYAb7ghnGglvPmm+1FHuZv5qksuCWm8sWNDEExPae7bF/ZTz55h/TffHIIahKDbvXsYf+utIX0J7t/6VrKHefTR4Xn69Oxt/OlPQ7lTTgntPfjg0J6XXgoH+EmTwolQts/83r3hc9qqVUij3nVXWOY999QoeiAEiWHAyynDdwF3pZV5GRgWvS4BPgQs23KbXZCor+rqmmeLuZo/P3t3vLra/dFHff2IEeHgnLjw3aeP+0knhXRRpmsEa9eGtEqifOoZWPryE72B1DSBe+iJQLgol2rOnFC+W7dk8HAPQeqVV0Kgqu0CcR3Uuq+nTHH/1Kdqdu0TF47PPLPBdYh1//1hHZ07h/RjbScKM2eG8r16hdy0ezjInnxyGN+69SftmDZtWnhfHHNMMui2ahXKZMqfL12a7J0k9nfi0b59WGfPnvuPr2+AcA8H+C5dQnBcuza+3HvvhRRb4j2we3foYSV6CIcdFtIyJSWhNz19et0/1xs3hpMSCPs+cUa/cWM4W4dwLW3q1DB+375w4C8tDT3MupzQPf10CLwQ0q2pabf6mD07uQ+HDMn4OW+qIGGhbNMzs8uAs939G9HwVcCJ7n5TSpmFUZnV0fDyqMyHacsaBYwCKCsrG/Lb3/42pzpVVlbSsWPHnOZtyRLttr17wR0vLa3TfO3ef58O77/PpmHD8NatY8u13rmTfe3a1RjfbdYstnzuc+xr336/8R2XLWN39+7s7datfg2ph5z3tTs9p01j63HHsbtXr8avGFD64Yf0/f3vWXPxxezp0aNudZo+na2f+Qy7e/b8ZLTt2cOACRPYctxxbD7xRCCl3dXVtF+1ik5LltBp6VIqjziCdV/+cuwqus2aRdd589g+YACVRx/N9v798cTf/AKlmzfTcdky2nz0ERtPO43qOr6HUh20Zg1VnTtTlcN+6Tp3Lr1efRXbtw+qq9nbtSsrr7ySqk6d6r2v269cyc4+fWp8DjpUVLC7Z0+qOnfeb3zbdeuoLi2t8/u184IFdH/jDVZcdRXVGT4XddVqzx56v/QSm4YNy/herG+7Tz311LnuPrTWgnWJJI3xAC4DfpUyfBUwJq3MQuDQlOHlQI9sy23xPYkCKMZ2F2Ob3Yuz3cXYZvem60nk88t0a4B+KcOHRuMyljGzEqAz0ICvMoqISEPkM0i8CRxlZgPNrJRwYTr9l+6mANdEry8DXo0inoiIFEDe/r7U3avM7CbCxenWwHh3X2Rm3yd0e6YAjwITzKwC2EwIJCIiUiB5/Y9rd58KTE0bd1/K613AV/JZJxERiacf+BMRkVgKEiIiEktBQkREYilIiIhIrLx947qpmNlGINd/lelB+OmPYlOM7S7GNkNxtrsY2wz1b3d/d+9ZW6EWHyQawszmeF2+ln6AKcZ2F2OboTjbXYxthqZrt9JNIiISS0FCRERiFXuQGFfoChRIMba7GNsMxdnuYmwzNFG7i/qahIiIZFfsPQkREclCQUJERGIVbZAws7PNbKmZVZjZnYWuT0OYWT8zm2Zmi81skZndEo3vZmavmNmy6LlrNN7M7OGo7W+b2eCUZV0TlV9mZtfErbO5MLPWZjbfzF6Ihgea2eyobROjn6XHzNpGwxXR9AEpy7grGr/UzM4qTEvqzsy6mNmzZrbEzN41s2EH+r42s9ui9/ZCM3vazA46EPe1mY03sw3Rv3QmxjXavjWzIWb2TjTPw2ZmtVaqLv9MdKA9CD9Vvhw4HCgF3gKOLXS9GtCePsDg6HUn4G/AscB/AndG4+8Efhy9Phd4CTDgJGB2NL4b8F703DV63bXQ7aul7bcDTwEvRMPPAJdHr8cCN0avvwmMjV5fDkyMXh8b7f+2wMDofdG60O2qpc1PAN+IXpcCXQ7kfQ30Bf4OtEvZxyMPxH0NnAIMBhamjGu0fQu8EZW1aN5zaq1ToTdKgXbEMODllOG7gLsKXa9GbN8fgC8BS4E+0bg+wNLo9SPA11LKL42mfw14JGX8fuWa24Pw74Z/Bk4DXoje+B8CJen7mfA/JsOi1yVROUvf96nlmuOD8G+Nfye66SR9Hx6I+zoKEquig15JtK/POlD3NTAgLUg0yr6Npi1JGb9fubhHsaabEm+6hNXRuBYv6loPAmYDZe7+QTRpHVAWvY5rf0vbLj8D/hWojoa7Ax+7e1U0nFr/T9oWTd8SlW9pbR4IbAQei9JsvzKzDhzA+9rd1wAPAe8DHxD23VwO/H2d0Fj7tm/0On18VsUaJA5IZtYReA641d23pk7zcOpwwNzvbGbnARvcfW6h65JnJYR0xC/dfRCwnZCC+MQBuK+7AhcSAuQhQAfg7IJWqkAKsW+LNUisAfqlDB8ajWuxzKwNIUD8xt0nRaPXm1mfaHofYEM0Pq79LWm7DAcuMLMVwG8JKaf/BrqYWeIfF1Pr/0nboumdgU20rDZDOPtb7e6zo+FnCUHjQN7XZwB/d/eN7r4XmETY/wf6vk5orH27JnqdPj6rYg0SbwJHRXdHlBIubk0pcJ1yFt2h8CjwrruPTpk0BUjc2XAN4VpFYvzV0d0RJwFbou7sy8CZZtY1Ons7MxrX7Lj7Xe5+qLsPIOy/V939CmAacFlULL3NiW1xWVTeo/GXR3fEDASOIlzca5bcfR2wysw+FY06HVjMAbyvCWmmk8ysffReT7T5gN7XKRpl30bTtprZSdF2vDplWfEKfZGmgBeHziXcBbQc+PdC16eBbflHQhf0bWBB9DiXkIf9M7AM+BPQLSpvwC+itr8DDE1Z1teBiuhxbaHbVsf2jyB5d9PhhA9+BfA7oG00/qBouCKafnjK/P8ebYul1OFuj0I/gOOBOdH+nky4g+WA3tfA94AlwEJgAuEOpQNuXwNPE6677CX0Gq9rzH0LDI224XJgDGk3QGR66Gc5REQkVrGmm0REpA4UJEREJJaChIiIxFKQEBGRWAoSIiISS0FCpJ7M7HGLfnVW5ECnW2BF6snMOhM+Ox+bWTnhx9huKnC1RJpESe1FRCSVu29p7GWaWam772ns5Yo0lHoSIvVkZo8DPQg/QZ3+Zz0D3X2FmR0L/Bfh/wF2Er4xe5uHn9VIXcYM4Gag1N175aUBIvWgaxIiubsFmAk8Rvit/j6E31XqA7xG+PmDEwg/UNcR+IOZpX7mvgh8jvCLpqfnsd4idaZ0k0iO3H2Lme0BdiR6CABmdiPwlrv/W8q4q4HNhN/OSfyo3C7g6+6+O4/VFqkXBQmRxjcEOMXMKjNMO4JkkFioACHNnYKESONrBbwIfCfDtPUpr7fnpzoiuVOQEGmYPUDrtHHzgH8CVnr4kxyRFksXrkUaZgVwgpkNMLMe0YXpXxD+DW2imZ1oZoeb2RlmNs7MOhW0tiL1pCAh0jAPEXoTi4GNwGHuvpbw95rVwB+BRYTAsTt6iLQY+p6EiIjEUk9CRERiKUiIiEgsBQkREYmlICEiIrEUJEREJJaChIiIxFKQEBGRWAoSIiIS6/8DEjKB7CHNkywAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#画出训练过程中Loss的变化曲线\n",
    "plt.figure()\n",
    "plt.title(\"train loss\", fontsize=24)\n",
    "plt.xlabel(\"iter\", fontsize=14)\n",
    "plt.ylabel(\"loss\", fontsize=14)\n",
    "plt.plot(iters, losses,color='red',label='train loss') \n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.5.2 使用VisualDL可视化分析\n",
    "\n",
    "VisualDL是飞桨可视化分析工具，以丰富的图表呈现训练参数变化趋势、数据样本、模型结构、PR曲线、ROC曲线、高维数据分布等。帮助用户清晰直观地理解深度学习模型训练过程及模型结构，进而实现高效的模型调优。与PLT库相比，VisualDL是更适合深度学习建模使用的可视化工具。\n",
    "\n",
    "**推荐安装方式**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 安装VisualDL\n",
    "!python -m pip install visualdl -i https://mirror.baidu.com/pypi/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**使用方式**：\n",
    "\n",
    "VisualDL将训练过程中的数据、参数等信息储存至日志文件中后，启动面板即可查看可视化结果。\n",
    "\n",
    "**1. 记录日志**\n",
    "\n",
    "VisualDL的后端提供了Python SDK，可通过LogWriter定制一个日志记录器，接口如下：\n",
    "\n",
    "```\n",
    "class LogWriter(logdir=None,\n",
    "                max_queue=10,\n",
    "                flush_secs=120,\n",
    "                filename_suffix='',\n",
    "                display_name='',\n",
    "                file_name='',\n",
    "                **kwargs)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss is: [3.8976812], acc is [0.125]\r\n",
      "epoch: 0, batch: 100, loss is: [0.24494784], acc is [0.921875]\r\n",
      "epoch: 0, batch: 200, loss is: [0.26378095], acc is [0.921875]\r\n",
      "epoch: 0, batch: 300, loss is: [0.22967383], acc is [0.890625]\r\n",
      "epoch: 0, batch: 400, loss is: [0.10998115], acc is [0.96875]\r\n",
      "epoch: 0, batch: 500, loss is: [0.08789912], acc is [0.96875]\r\n",
      "epoch: 0, batch: 600, loss is: [0.06132765], acc is [1.]\r\n",
      "epoch: 0, batch: 700, loss is: [0.25114188], acc is [0.921875]\r\n",
      "epoch: 0, batch: 800, loss is: [0.13402592], acc is [0.9375]\r\n",
      "epoch: 0, batch: 900, loss is: [0.05303773], acc is [0.984375]\r\n",
      "epoch: 1, batch: 0, loss is: [0.05307241], acc is [0.984375]\r\n",
      "epoch: 1, batch: 100, loss is: [0.04524157], acc is [0.984375]\r\n",
      "epoch: 1, batch: 200, loss is: [0.04033208], acc is [0.984375]\r\n",
      "epoch: 1, batch: 300, loss is: [0.04626527], acc is [0.984375]\r\n",
      "epoch: 1, batch: 400, loss is: [0.01260194], acc is [1.]\r\n",
      "epoch: 1, batch: 500, loss is: [0.06764157], acc is [0.96875]\r\n",
      "epoch: 1, batch: 600, loss is: [0.09227023], acc is [0.96875]\r\n",
      "epoch: 1, batch: 700, loss is: [0.07254598], acc is [0.96875]\r\n",
      "epoch: 1, batch: 800, loss is: [0.1025949], acc is [0.953125]\r\n",
      "epoch: 1, batch: 900, loss is: [0.00322359], acc is [1.]\r\n",
      "epoch: 2, batch: 0, loss is: [0.02664608], acc is [1.]\r\n",
      "epoch: 2, batch: 100, loss is: [0.04558125], acc is [1.]\r\n",
      "epoch: 2, batch: 200, loss is: [0.05848975], acc is [0.984375]\r\n",
      "epoch: 2, batch: 300, loss is: [0.00495513], acc is [1.]\r\n",
      "epoch: 2, batch: 400, loss is: [0.05350171], acc is [0.984375]\r\n",
      "epoch: 2, batch: 500, loss is: [0.19869223], acc is [0.953125]\r\n",
      "epoch: 2, batch: 600, loss is: [0.02840726], acc is [1.]\r\n",
      "epoch: 2, batch: 700, loss is: [0.03301933], acc is [0.984375]\r\n",
      "epoch: 2, batch: 800, loss is: [0.13366723], acc is [0.9375]\r\n",
      "epoch: 2, batch: 900, loss is: [0.1324224], acc is [0.96875]\r\n",
      "epoch: 3, batch: 0, loss is: [0.06951778], acc is [0.984375]\r\n",
      "epoch: 3, batch: 100, loss is: [0.1105411], acc is [0.953125]\r\n",
      "epoch: 3, batch: 200, loss is: [0.05074476], acc is [0.984375]\r\n",
      "epoch: 3, batch: 300, loss is: [0.05399875], acc is [0.96875]\r\n",
      "epoch: 3, batch: 400, loss is: [0.0281655], acc is [0.984375]\r\n",
      "epoch: 3, batch: 500, loss is: [0.04794339], acc is [0.984375]\r\n",
      "epoch: 3, batch: 600, loss is: [0.06038764], acc is [0.96875]\r\n",
      "epoch: 3, batch: 700, loss is: [0.00618259], acc is [1.]\r\n",
      "epoch: 3, batch: 800, loss is: [0.05110959], acc is [0.96875]\r\n",
      "epoch: 3, batch: 900, loss is: [0.06365701], acc is [0.984375]\r\n",
      "epoch: 4, batch: 0, loss is: [0.00282368], acc is [1.]\r\n",
      "epoch: 4, batch: 100, loss is: [0.05808049], acc is [0.96875]\r\n",
      "epoch: 4, batch: 200, loss is: [0.02086016], acc is [1.]\r\n",
      "epoch: 4, batch: 300, loss is: [0.05191016], acc is [0.96875]\r\n",
      "epoch: 4, batch: 400, loss is: [0.07787728], acc is [0.96875]\r\n",
      "epoch: 4, batch: 500, loss is: [0.01578094], acc is [1.]\r\n",
      "epoch: 4, batch: 600, loss is: [0.11052053], acc is [0.953125]\r\n",
      "epoch: 4, batch: 700, loss is: [0.07256945], acc is [0.96875]\r\n",
      "epoch: 4, batch: 800, loss is: [0.0027408], acc is [1.]\r\n",
      "epoch: 4, batch: 900, loss is: [0.00524686], acc is [1.]\r\n",
      "epoch: 5, batch: 0, loss is: [0.07757618], acc is [0.984375]\r\n",
      "epoch: 5, batch: 100, loss is: [0.00286792], acc is [1.]\r\n",
      "epoch: 5, batch: 200, loss is: [0.01645469], acc is [0.984375]\r\n",
      "epoch: 5, batch: 300, loss is: [0.09424831], acc is [0.984375]\r\n",
      "epoch: 5, batch: 400, loss is: [0.04262222], acc is [0.984375]\r\n",
      "epoch: 5, batch: 500, loss is: [0.00665575], acc is [1.]\r\n",
      "epoch: 5, batch: 600, loss is: [0.07796165], acc is [0.96875]\r\n",
      "epoch: 5, batch: 700, loss is: [0.04314306], acc is [0.984375]\r\n",
      "epoch: 5, batch: 800, loss is: [0.00889275], acc is [1.]\r\n",
      "epoch: 5, batch: 900, loss is: [0.03673035], acc is [0.984375]\r\n",
      "epoch: 6, batch: 0, loss is: [0.03669504], acc is [1.]\r\n",
      "epoch: 6, batch: 100, loss is: [0.12926766], acc is [0.9375]\r\n",
      "epoch: 6, batch: 200, loss is: [0.05695032], acc is [0.96875]\r\n",
      "epoch: 6, batch: 300, loss is: [0.00497303], acc is [1.]\r\n",
      "epoch: 6, batch: 400, loss is: [0.00785465], acc is [1.]\r\n",
      "epoch: 6, batch: 500, loss is: [0.03658008], acc is [0.984375]\r\n",
      "epoch: 6, batch: 600, loss is: [0.00893693], acc is [1.]\r\n",
      "epoch: 6, batch: 700, loss is: [0.03663061], acc is [0.984375]\r\n",
      "epoch: 6, batch: 800, loss is: [0.12396517], acc is [0.953125]\r\n",
      "epoch: 6, batch: 900, loss is: [0.00987581], acc is [1.]\r\n",
      "epoch: 7, batch: 0, loss is: [0.00513407], acc is [1.]\r\n",
      "epoch: 7, batch: 100, loss is: [0.00193752], acc is [1.]\r\n",
      "epoch: 7, batch: 200, loss is: [0.04616558], acc is [0.984375]\r\n",
      "epoch: 7, batch: 300, loss is: [0.0307204], acc is [0.984375]\r\n",
      "epoch: 7, batch: 400, loss is: [0.03893897], acc is [0.984375]\r\n",
      "epoch: 7, batch: 500, loss is: [0.06653114], acc is [0.984375]\r\n",
      "epoch: 7, batch: 600, loss is: [0.03551684], acc is [0.96875]\r\n",
      "epoch: 7, batch: 700, loss is: [0.04304881], acc is [0.984375]\r\n",
      "epoch: 7, batch: 800, loss is: [0.0891945], acc is [0.984375]\r\n",
      "epoch: 7, batch: 900, loss is: [0.04357353], acc is [0.984375]\r\n",
      "epoch: 8, batch: 0, loss is: [0.00033292], acc is [1.]\r\n",
      "epoch: 8, batch: 100, loss is: [0.00028144], acc is [1.]\r\n",
      "epoch: 8, batch: 200, loss is: [0.00887554], acc is [1.]\r\n",
      "epoch: 8, batch: 300, loss is: [0.05767912], acc is [0.96875]\r\n",
      "epoch: 8, batch: 400, loss is: [0.03788796], acc is [0.984375]\r\n",
      "epoch: 8, batch: 500, loss is: [0.03715087], acc is [0.984375]\r\n",
      "epoch: 8, batch: 600, loss is: [0.04141467], acc is [0.984375]\r\n",
      "epoch: 8, batch: 700, loss is: [0.03894728], acc is [0.984375]\r\n",
      "epoch: 8, batch: 800, loss is: [0.0720887], acc is [0.96875]\r\n",
      "epoch: 8, batch: 900, loss is: [0.00421867], acc is [1.]\r\n",
      "epoch: 9, batch: 0, loss is: [0.03633005], acc is [0.984375]\r\n",
      "epoch: 9, batch: 100, loss is: [0.00124391], acc is [1.]\r\n",
      "epoch: 9, batch: 200, loss is: [0.01813628], acc is [0.984375]\r\n",
      "epoch: 9, batch: 300, loss is: [0.00529736], acc is [1.]\r\n",
      "epoch: 9, batch: 400, loss is: [0.12610942], acc is [0.9375]\r\n",
      "epoch: 9, batch: 500, loss is: [0.02882565], acc is [0.984375]\r\n",
      "epoch: 9, batch: 600, loss is: [0.03620434], acc is [0.984375]\r\n",
      "epoch: 9, batch: 700, loss is: [0.00019643], acc is [1.]\r\n",
      "epoch: 9, batch: 800, loss is: [0.04434416], acc is [0.984375]\r\n",
      "epoch: 9, batch: 900, loss is: [0.07912198], acc is [0.984375]\r\n"
     ]
    }
   ],
   "source": [
    "#引入VisualDL库，并设定保存作图数据的文件位置\n",
    "from visualdl import LogWriter\n",
    "log_writer = LogWriter(logdir=\"./log\")\n",
    "\n",
    "def train(model):\n",
    "    model.train()\n",
    "    \n",
    "    opt = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\n",
    "    \n",
    "    EPOCH_NUM = 10\n",
    "    iter = 0\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #准备数据，变得更加简洁\n",
    "            images, labels = data\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.to_tensor(labels)\n",
    "            \n",
    "            #前向计算的过程，同时拿到模型输出值和分类准确率\n",
    "            predicts, avg_acc = model(images, labels)\n",
    "            #计算损失，取一个批次样本损失的平均值\n",
    "            loss = F.cross_entropy(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "            \n",
    "            #每训练了100批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 100 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}, acc is {}\".format(epoch_id, batch_id, avg_loss.numpy(), avg_acc.numpy()))\n",
    "                log_writer.add_scalar(tag = 'acc', step = iter, value = avg_acc.numpy())\n",
    "                log_writer.add_scalar(tag = 'loss', step = iter, value = avg_loss.numpy())\n",
    "                iter = iter + 100\n",
    "\n",
    "            #后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "    #保存模型参数\n",
    "    paddle.save(model.state_dict(), 'mnist.pdparams')\n",
    "    \n",
    "model = MNIST()\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 启动面板**\n",
    "\n",
    "共有两种启动方式：\n",
    "\n",
    "在命令行启动：使用命令行启动VisualDL面板，命令格式如下\n",
    "\n",
    "`visualdl --logdir <dir_1, dir_2, ... , dir_n> --model <model_file> --host <host> --port <port> --cache-timeout <cache_timeout> --language <language> --public-path <public_path> --api-only`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!visualdl --logdir /home/aistudio/log --port 8080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在Python脚本中启动：支持在Python脚本中启动VisualDL面板，接口如下\n",
    "\n",
    "```\n",
    "visualdl.server.app.run(logdir,\n",
    "                        model=\"path/to/model\",\n",
    "                        host=\"127.0.0.1\",\n",
    "                        port=8080,\n",
    "                        cache_timeout=20,\n",
    "                        language=None,\n",
    "                        public_path=None,\n",
    "                        api_only=False,\n",
    "                        open_browser=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import visualdl\n",
    "import visualdl.server.app \n",
    "visualdl.server.app.run('/home/aistudio/log',\n",
    "                        host=\"127.0.0.1\",\n",
    "                        port=8080,\n",
    "                        cache_timeout=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 使用LogReader获取日志中的数据**\n",
    "\n",
    "VisualDL的后端也提供了获取日志数据的组件LogReader，可通过其获取日志中任意数据，接口如下：\n",
    "\n",
    "`class LogReader(file_path='')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作业题 2-4\n",
    "\n",
    "* 将普通神经网络模型的每层输出打印，观察内容。\n",
    "* 将分类准确率的指标 用PLT库画图表示。\n",
    "* 通过分类准确率，判断以采用不同损失函数训练模型的效果优劣。\n",
    "* 作图比较：随着训练进行，模型在训练集和测试集上的Loss曲线。\n",
    "* 调节正则化权重，观察4的作图曲线的变化，并分析原因。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
