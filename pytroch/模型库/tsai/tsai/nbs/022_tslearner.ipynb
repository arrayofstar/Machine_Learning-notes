{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp tslearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSLearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New set of time series learners with a new sklearn-like API that simplifies the learner creation. The following classes are included: \n",
    "\n",
    "  * TSClassifier\n",
    "  * TSRegressor\n",
    "  * TSForecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from fastai.learner import Learner\n",
    "from fastai.optimizer import Adam\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.losses import *\n",
    "from tsai.imports import *\n",
    "from tsai.learner import *\n",
    "from tsai.data.validation import *\n",
    "from tsai.data.core import *\n",
    "from tsai.models.InceptionTimePlus import *\n",
    "from tsai.models.utils import *\n",
    "from tsai.metrics import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSClassifier API\n",
    "***\n",
    "\n",
    "**Commonly used arguments:**\n",
    "    \n",
    "* **X:** array-like of shape (n_samples, n_steps) or (n_samples, n_features, n_steps) with the input time series samples. Internally, they will be converted to torch tensors.\n",
    "* **y:** array-like of shape (n_samples), (n_samples, n_outputs) or (n_samples, n_features, n_outputs) with the target. Internally, they will be converted to torch tensors. Default=None. None is used for unlabeled datasets. \n",
    "* **splits:** lists of indices used to split data between train and validation. Default=None. If no splits are passed, data will be split 100:0 between train and test without shuffling.\n",
    "* **tfms:** item transforms that will be applied to each sample individually. Default:None.\n",
    "* **batch_tfms:** transforms applied to each batch. Default=None. \n",
    "* **pipelines:** store sklearn-type pipelines that can then be applied to pandas dataframes with transform or inverse_transform methods. Default=None. \n",
    "* **bs:** batch size (if batch_size is provided then batch_size will override bs). An int or a list of ints can be passed. Default=`[64, 128]`. If a list of ints, the first one will be used for training, and the second for the valid (batch size can be larger as it doesn't require backpropagation which consumes more memory). \n",
    "* **arch:** indicates which architecture will be used. Alternatively, you can pass an instantiated model. Default: InceptionTimePlus.\n",
    "* **arch_config:** keyword arguments passed to the selected architecture. Default={}.\n",
    "* **pretrained:** indicates if pretrained model weights will be used. Default=False.\n",
    "* **weights_path:** indicates the path to the pretrained weights in case they are used.\n",
    "* **loss_func:** allows you to pass any loss function. Default=None (in which case CrossEntropyLossFlat() is applied).\n",
    "* **opt_func:** allows you to pass an optimizer. Default=Adam.\n",
    "* **lr:** learning rate. Default=0.001.\n",
    "* **metrics:** list of metrics passed to the Learner. Default=accuracy.\n",
    "* **cbs:** list of callbacks passed to the Learner. Default=None.\n",
    "* **wd:** is the default weight decay used when training the model. Default=None.\n",
    "\n",
    "**Less frequently used arguments:**\n",
    "\n",
    "* **sel_vars:** used to select which of the features in multivariate datasets are used. Default=None means all features are used. If necessary a list-like of indices can be used (eg.`[0,3,5]`).\n",
    "* **sel_steps:** used to select the steps used. Default=None means all steps are used. If necessary a list-like of indices can be used (eg. `slice(-50, None)` will select the last 50 steps from each time series).\n",
    "* **weights:** indicates a sample weight per instance. Used to pass pass a probability to the train dataloader sampler. Samples with more weight will be selected more often during training. \n",
    "* **partial_n:** select randomly partial quantity of data at each epoch. Used to reduce the training size (for example for testing purposes). int or float can be used.\n",
    "* **vocab:** vocabulary used to transform the target. Only required when transformed is not perform by a dataloader's tfm (external transforms).\n",
    "* **train_metrics:** flag used to display metrics in the training set. Defaults to False.\n",
    "* **valid_metrics:** flag used to display metrics in the validtion set. Defaults to True.\n",
    "* **inplace:** indicates whether tfms are applied during instantiation or on-the-fly. Default=True, which means that tfms will be applied during instantiation. This results in a faster training, but it can only be used when data fits in memory. Otherwise set it to False. \n",
    "* **shuffle_train:** indicates whether to shuffle the training set every time the dataloader is fully read/iterated or not. This doesn't have an impact on the validation set which is never shuffled. Default=True.\n",
    "* **drop_last:** if True the last incomplete training batch is dropped (thus ensuring training batches of equal size). This doesn't have an impact on the validation set where samples are never dropped. Default=True.\n",
    "* **num_workers:** num_workers (int): how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. Default=0. \n",
    "* **do_setup:** ndicates if the Pipeline.setup method should be called during initialization. Default=True.\n",
    "* **device:** Defaults to default_device() which is CUDA by default. You can specify device as `torch.device('cpu').\n",
    "* **seed:** Set to an int to ensure reprodubibility. Default=None.\n",
    "* **verbose:** controls the verbosity when fitting and predicting.\n",
    "* **exclude_head:** indicates whether the head of the pretrained model needs to be removed or not. Default=True.\n",
    "* **cut:** indicates the position where the pretrained model head needs to be cut. Defaults=-1.\n",
    "* **init:** allows you to set to None (no initialization applied), set to True (in which case nn.init.kaiming_normal_ will be applied) or pass an initialization. Default=None.\n",
    "* **splitter:** To do transfer learning, you need to pass a splitter to Learner. This should be a function taking the model and returning a collection of parameter groups, e.g. a list of list of parameters. Default=trainable_params. If the model has a backbone and a head, it will then be split in those 2 groups.\n",
    "* **path** and **model_dir:** are used to save and/or load models. Often path will be inferred from dls, but you can override it or pass a Path object to model_dir.\n",
    "* **wd_bn_bias:** controls if weight decay is applied to BatchNorm layers and bias. Default=False.\n",
    "train_bn=True\n",
    "* **moms:** the default momentums used in Learner.fit_one_cycle. Default=(0.95, 0.85, 0.95)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TSClassifier(Learner):\n",
    "    def __init__(self, X, y=None, splits=None, tfms=None, inplace=True, sel_vars=None, sel_steps=None, weights=None, partial_n=None, vocab=None,\n",
    "                 train_metrics=False, valid_metrics=True, bs=[64, 128], batch_size=None, batch_tfms=None, pipelines=None,\n",
    "                 shuffle_train=True, drop_last=True, num_workers=0, do_setup=True, device=None, seed=None,\n",
    "                 arch=None, arch_config={}, pretrained=False, weights_path=None, exclude_head=True, cut=-1, init=None,\n",
    "                 loss_func=None, opt_func=Adam, lr=0.001, metrics=accuracy, cbs=None, wd=None, wd_bn_bias=False,\n",
    "                 train_bn=True, moms=(0.95, 0.85, 0.95),  path='.', model_dir='models', splitter=trainable_params, verbose=False):\n",
    "\n",
    "        # Seed\n",
    "        if seed is not None:\n",
    "            set_seed(seed, reproducible=True)\n",
    "        \n",
    "        # Batch size\n",
    "        if batch_size is not None:\n",
    "            bs = batch_size\n",
    "\n",
    "        # DataLoaders\n",
    "        dls = get_ts_dls(X, y=y, splits=splits, sel_vars=sel_vars, sel_steps=sel_steps, tfms=tfms, inplace=inplace, vocab=vocab,\n",
    "                         path=path, bs=bs, batch_tfms=batch_tfms, num_workers=num_workers, weights=weights, partial_n=partial_n, \n",
    "                         device=device, shuffle_train=shuffle_train, drop_last=drop_last)\n",
    "        \n",
    "        if loss_func is None:\n",
    "            if hasattr(dls, 'loss_func'): loss_func = dls.loss_func\n",
    "            elif hasattr(dls, 'cat') and not dls.cat: loss_func = MSELossFlat()\n",
    "            elif hasattr(dls, 'train_ds') and hasattr(dls.train_ds, 'loss_func'): loss_func = dls.train_ds.loss_func\n",
    "            else: loss_func = CrossEntropyLossFlat()\n",
    "        \n",
    "        # Model\n",
    "        if isinstance(arch, nn.Module): \n",
    "            model = arch\n",
    "            if arch_config: \n",
    "                warnings.warn(\"You have passed arch_config to a model that is already intantiated. It will not have any effect.\", UserWarning)\n",
    "            if init is not None: \n",
    "                warnings.warn(\"You have passed init to a model that is already intantiated. It will not have any effect.\", UserWarning)\n",
    "        else:\n",
    "            if init is True:\n",
    "                init = nn.init.kaiming_normal_\n",
    "            if arch is None:\n",
    "                arch = InceptionTimePlus\n",
    "            elif isinstance(arch, str): arch = get_arch(arch)\n",
    "            # if 'xresnet' in arch.__name__.lower() and not '1d' in arch.__name__.lower():\n",
    "            #     model = build_tsimage_model(arch, dls=dls, pretrained=pretrained, init=init, device=device, verbose=verbose, arch_config=arch_config)\n",
    "            # elif 'tabularmodel' in arch.__name__.lower():\n",
    "            #     model = build_tabular_model(arch, dls=dls, device=device, arch_config=arch_config)\n",
    "            # else:\n",
    "            #     model = build_ts_model(arch, dls=dls, device=device, verbose=verbose, pretrained=pretrained, weights_path=weights_path,\n",
    "            #                            exclude_head=exclude_head, cut=cut, init=init, arch_config=arch_config)\n",
    "            model = build_ts_model(arch, dls=dls, device=device, verbose=verbose, pretrained=pretrained, weights_path=weights_path,\n",
    "                                    exclude_head=exclude_head, cut=cut, init=init, arch_config=arch_config)\n",
    "        try:\n",
    "            setattr(model, \"__name__\", arch.__name__)\n",
    "        except:\n",
    "            setattr(model, \"__name__\", arch.__class__.__name__)\n",
    "        \n",
    "        if hasattr(model, \"backbone\") and hasattr(model, \"head\"):\n",
    "            splitter = ts_splitter\n",
    "            \n",
    "        if pipelines is not None:\n",
    "            pipelines = listify(pipelines)\n",
    "        setattr(self, \"pipelines\", pipelines)\n",
    "        \n",
    "        super().__init__(dls, model, loss_func=loss_func, opt_func=opt_func, lr=lr, cbs=cbs, metrics=metrics, path=path, splitter=splitter,\n",
    "                         model_dir=model_dir, wd=wd, wd_bn_bias=wd_bn_bias, train_bn=train_bn, moms=moms)\n",
    "\n",
    "        if hasattr(self, \"recorder\"):\n",
    "            self.recorder.train_metrics = train_metrics\n",
    "            if splits is None or not hasattr(splits[0], \"__len__\") or len(splits) == 1 or \\\n",
    "                (len(splits) >= 2 and (splits[1] is None or not hasattr(splits[1], \"__len__\"))): \n",
    "                self.recorder.valid_metrics = False\n",
    "            else:\n",
    "                self.recorder.valid_metrics = valid_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.data.external import *\n",
    "from tsai.data.preprocessing import *\n",
    "from tsai.models.InceptionTimePlus import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With validation split\n",
    "X, y, splits = get_classification_data('OliveOil', split_data=False)\n",
    "tfms = [None, TSClassification()]\n",
    "batch_tfms = [TSStandardize(by_sample=True)]\n",
    "learn = TSClassifier(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms, metrics=accuracy, arch=InceptionTimePlus, arch_config=dict(fc_dropout=.5), \n",
    "                     train_metrics=True)\n",
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Without validation split\n",
    "X, y, splits = get_classification_data('OliveOil', split_data=False)\n",
    "splits = (splits[0], None)\n",
    "tfms = [None, TSClassification()]\n",
    "batch_tfms = [TSStandardize(by_sample=True)]\n",
    "learn = TSClassifier(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms, metrics=accuracy, arch=InceptionTimePlus, arch_config=dict(fc_dropout=.5), \n",
    "                     train_metrics=True)\n",
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:53] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 5\n",
    "X = torch.rand(8, 2, 50)\n",
    "y = torch.randint(0, num_classes, (len(X), 1, 50))\n",
    "splits = TimeSplitter(show_plot=False)(y)\n",
    "vocab = np.arange(num_classes)\n",
    "\n",
    "fail_test = []\n",
    "for arch in all_arch_names:\n",
    "    if not \"plus\" in arch.lower(): continue\n",
    "    try:\n",
    "        fcst = TSClassifier(X, y, splits=splits, arch=arch, metrics=accuracy, vocab=vocab)\n",
    "        with ContextManagers([fcst.no_bar(), fcst.no_logging()]):\n",
    "            fcst.fit_one_cycle(1, 1e-3)\n",
    "    except Exception as e: \n",
    "        fail_test.append(arch)\n",
    "        print(arch, e)\n",
    "\n",
    "test_eq(fail_test, [])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSRegressor API\n",
    "***\n",
    "\n",
    "**Commonly used arguments:**\n",
    "    \n",
    "* **X:** array-like of shape (n_samples, n_steps) or (n_samples, n_features, n_steps) with the input time series samples. Internally, they will be converted to torch tensors.\n",
    "* **y:** array-like of shape (n_samples), (n_samples, n_outputs) or (n_samples, n_features, n_outputs) with the target. Internally, they will be converted to torch tensors. Default=None. None is used for unlabeled datasets. \n",
    "* **splits:** lists of indices used to split data between train and validation. Default=None. If no splits are passed, data will be split 100:0 between train and test without shuffling.\n",
    "* **tfms:** item transforms that will be applied to each sample individually. Default=None.\n",
    "* **batch_tfms:** transforms applied to each batch. Default=None. \n",
    "* **pipelines:** store sklearn-type pipelines that can then be applied to pandas dataframes with transform or inverse_transform methods. Default=None. \n",
    "* **bs:** batch size (if batch_size is provided then batch_size will override bs). An int or a list of ints can be passed. Default=`[64, 128]`. If a list of ints, the first one will be used for training, and the second for the valid (batch size can be larger as it doesn't require backpropagation which consumes more memory). \n",
    "* **arch:** indicates which architecture will be used. Alternatively, you can pass an instantiated model. Default: InceptionTimePlus.\n",
    "* **arch_config:** keyword arguments passed to the selected architecture. Default={}.\n",
    "* **pretrained:** indicates if pretrained model weights will be used. Default=False.\n",
    "* **weights_path:** indicates the path to the pretrained weights in case they are used.\n",
    "* **loss_func:** allows you to pass any loss function. Default=None (in which case CrossEntropyLossFlat() is applied).\n",
    "* **opt_func:** allows you to pass an optimizer. Default=Adam.\n",
    "* **lr:** learning rate. Default=0.001.\n",
    "* **metrics:** list of metrics passed to the Learner. Default=None.\n",
    "* **cbs:** list of callbacks passed to the Learner. Default=None.\n",
    "* **wd:** is the default weight decay used when training the model. Default=None.\n",
    "\n",
    "**Less frequently used arguments:**\n",
    "\n",
    "* **sel_vars:** used to select which of the features in multivariate datasets are used. Default=None means all features are used. If necessary a list-like of indices can be used (eg.`[0,3,5]`).\n",
    "* **sel_steps:** used to select the steps used. Default=None means all steps are used. If necessary a list-like of indices can be used (eg. `slice(-50, None)` will select the last 50 steps from each time series).\n",
    "* **weights:** indicates a sample weight per instance. Used to pass pass a probability to the train dataloader sampler. Samples with more weight will be selected more often during training. \n",
    "* **partial_n:** select randomly partial quantity of data at each epoch. Used to reduce the training size (for example for testing purposes). int or float can be used.\n",
    "* **train_metrics:** flag used to display metrics in the training set. Defaults to False.\n",
    "* **valid_metrics:** flag used to display metrics in the validtion set. Defaults to True.\n",
    "* **inplace:** indicates whether tfms are applied during instantiation or on-the-fly. Default=True, which means that tfms will be applied during instantiation. This results in a faster training, but it can only be used when data fits in memory. Otherwise set it to False. \n",
    "* **shuffle_train:** indicates whether to shuffle the training set every time the dataloader is fully read/iterated or not. This doesn't have an impact on the validation set which is never shuffled. Default=True.\n",
    "* **drop_last:** if True the last incomplete training batch is dropped (thus ensuring training batches of equal size). This doesn't have an impact on the validation set where samples are never dropped. Default=True.\n",
    "* **num_workers:** num_workers (int): how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. Default=0. \n",
    "* **do_setup:** ndicates if the Pipeline.setup method should be called during initialization. Default=True.\n",
    "* **device:** Defaults to default_device() which is CUDA by default. You can specify device as `torch.device('cpu').\n",
    "* **seed:** Set to an int to ensure reprodubibility. Default=None.\n",
    "* **verbose:** controls the verbosity when fitting and predicting.\n",
    "* **exclude_head:** indicates whether the head of the pretrained model needs to be removed or not. Default=True.\n",
    "* **cut:** indicates the position where the pretrained model head needs to be cut. Defaults=-1.\n",
    "* **init:** allows you to set to None (no initialization applied), set to True (in which case nn.init.kaiming_normal_ will be applied) or pass an initialization. Default=None.\n",
    "* **splitter:** To do transfer learning, you need to pass a splitter to Learner. This should be a function taking the model and returning a collection of parameter groups, e.g. a list of list of parameters. Default=trainable_params. If the model has a backbone and a head, it will then be split in those 2 groups.\n",
    "* **path** and **model_dir:** are used to save and/or load models. Often path will be inferred from dls, but you can override it or pass a Path object to model_dir.\n",
    "* **wd_bn_bias:** controls if weight decay is applied to BatchNorm layers and bias. Default=False.\n",
    "train_bn=True\n",
    "* **moms:** the default momentums used in Learner.fit_one_cycle. Default=(0.95, 0.85, 0.95)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TSRegressor(Learner):\n",
    "    def __init__(self, X, y=None, splits=None, tfms=None, inplace=True, sel_vars=None, sel_steps=None, weights=None, partial_n=None, \n",
    "                 train_metrics=False, valid_metrics=True, bs=[64, 128], batch_size=None, batch_tfms=None, pipelines=None,\n",
    "                 shuffle_train=True, drop_last=True, num_workers=0, do_setup=True, device=None, seed=None,\n",
    "                 arch=None, arch_config={}, pretrained=False, weights_path=None, exclude_head=True, cut=-1, init=None,\n",
    "                 loss_func=None, opt_func=Adam, lr=0.001, metrics=None, cbs=None, wd=None, wd_bn_bias=False,\n",
    "                 train_bn=True, moms=(0.95, 0.85, 0.95),  path='.', model_dir='models', splitter=trainable_params, verbose=False):\n",
    "\n",
    "        # Seed\n",
    "        if seed is not None:\n",
    "            set_seed(seed, reproducible=True)\n",
    "        \n",
    "        \n",
    "        # Batch size\n",
    "        if batch_size is not None:\n",
    "            bs = batch_size\n",
    "\n",
    "        # DataLoaders\n",
    "        dls = get_ts_dls(X, y=y, splits=splits, sel_vars=sel_vars, sel_steps=sel_steps, tfms=tfms, inplace=inplace, \n",
    "                         path=path, bs=bs, batch_tfms=batch_tfms, num_workers=num_workers, weights=weights, partial_n=partial_n, \n",
    "                         device=device, shuffle_train=shuffle_train, drop_last=drop_last)\n",
    "\n",
    "        if loss_func is None:\n",
    "            if hasattr(dls, 'loss_func'): loss_func = dls.loss_func\n",
    "            elif hasattr(dls, 'cat') and not dls.cat: loss_func = MSELossFlat()\n",
    "            elif hasattr(dls, 'train_ds') and hasattr(dls.train_ds, 'loss_func'): loss_func = dls.train_ds.loss_func\n",
    "            else: loss_func = MSELossFlat()\n",
    "                \n",
    "        # Model\n",
    "        if isinstance(arch, nn.Module): \n",
    "            model = arch\n",
    "            if arch_config: \n",
    "                warnings.warn(\"You have passed arch_config to a model that is already intantiated. It will not have any effect.\", UserWarning)\n",
    "            if init is not None: \n",
    "                warnings.warn(\"You have passed init to a model that is already intantiated. It will not have any effect.\", UserWarning)\n",
    "        else:\n",
    "            if init is True:\n",
    "                init = nn.init.kaiming_normal_\n",
    "            if arch is None:\n",
    "                arch = InceptionTimePlus\n",
    "            elif isinstance(arch, str): arch = get_arch(arch)\n",
    "            # if 'xresnet' in arch.__name__.lower() and not '1d' in arch.__name__.lower():\n",
    "            #     model = build_tsimage_model(arch, dls=dls, pretrained=pretrained, init=init, device=device, verbose=verbose, arch_config=arch_config)\n",
    "            # elif 'tabularmodel' in arch.__name__.lower():\n",
    "            #     model = build_tabular_model(arch, dls=dls, device=device, arch_config=arch_config)\n",
    "            # else:\n",
    "            #     model = build_ts_model(arch, dls=dls, device=device, verbose=verbose, pretrained=pretrained, weights_path=weights_path,\n",
    "            #                        exclude_head=exclude_head, cut=cut, init=init, arch_config=arch_config)\n",
    "            model = build_ts_model(arch, dls=dls, device=device, verbose=verbose, pretrained=pretrained, weights_path=weights_path,\n",
    "                                exclude_head=exclude_head, cut=cut, init=init, arch_config=arch_config)\n",
    "        try:\n",
    "            setattr(model, \"__name__\", arch.__name__)\n",
    "        except:\n",
    "            setattr(model, \"__name__\", arch.__class__.__name__)\n",
    "        \n",
    "        if hasattr(model, \"backbone\") and hasattr(model, \"head\"):\n",
    "            splitter = ts_splitter\n",
    "            \n",
    "        if pipelines is not None:\n",
    "            pipelines = listify(pipelines)\n",
    "        setattr(self, \"pipelines\", pipelines)\n",
    "\n",
    "        super().__init__(dls, model, loss_func=loss_func, opt_func=opt_func, lr=lr, cbs=cbs, metrics=metrics, path=path, splitter=splitter,\n",
    "                         model_dir=model_dir, wd=wd, wd_bn_bias=wd_bn_bias, train_bn=train_bn, moms=moms) \n",
    "        \n",
    "        if hasattr(self, \"recorder\"):\n",
    "            self.recorder.train_metrics = train_metrics\n",
    "            if splits is None or not hasattr(splits[0], \"__len__\") or len(splits) == 1 or \\\n",
    "                (len(splits) >= 2 and (splits[1] is None or not hasattr(splits[1], \"__len__\"))): \n",
    "                self.recorder.valid_metrics = False\n",
    "            else:\n",
    "                self.recorder.valid_metrics = valid_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, splits = get_regression_data('AppliancesEnergy', split_data=False)\n",
    "if X is not None: # This is to prevent a test fail when the data server is not available\n",
    "    batch_tfms = [TSStandardize()]\n",
    "    learn = TSRegressor(X, y, splits=splits, batch_tfms=batch_tfms, arch=None, metrics=mae, bs=512, train_metrics=True)\n",
    "    learn.fit_one_cycle(1, 1e-4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSForecaster API\n",
    "***\n",
    "**Commonly used arguments:**\n",
    "    \n",
    "* **X:** array-like of shape (n_samples, n_steps) or (n_samples, n_features, n_steps) with the input time series samples. Internally, they will be converted to torch tensors.\n",
    "* **y:** array-like of shape (n_samples), (n_samples, n_outputs) or (n_samples, n_features, n_outputs) with the target. Internally, they will be converted to torch tensors. Default=None. None is used for unlabeled datasets. \n",
    "* **splits:** lists of indices used to split data between train and validation. Default=None. If no splits are passed, data will be split 100:0 between train and test without shuffling.\n",
    "* **tfms:** item transforms that will be applied to each sample individually. Default=None.\n",
    "* **batch_tfms:** transforms applied to each batch. Default=None. \n",
    "* **pipelines:** store sklearn-type pipelines that can then be applied to pandas dataframes with transform or inverse_transform methods. Default=None. \n",
    "* **bs:** batch size (if batch_size is provided then batch_size will override bs). An int or a list of ints can be passed. Default=`[64, 128]`. If a list of ints, the first one will be used for training, and the second for the valid (batch size can be larger as it doesn't require backpropagation which consumes more memory). \n",
    "* **arch:** indicates which architecture will be used. Alternatively, you can pass an instantiated model. Default: InceptionTimePlus.\n",
    "* **arch_config:** keyword arguments passed to the selected architecture. Default={}.\n",
    "* **pretrained:** indicates if pretrained model weights will be used. Default=False.\n",
    "* **weights_path:** indicates the path to the pretrained weights in case they are used.\n",
    "* **loss_func:** allows you to pass any loss function. Default=None (in which case CrossEntropyLossFlat() is applied).\n",
    "* **opt_func:** allows you to pass an optimizer. Default=Adam.\n",
    "* **lr:** learning rate. Default=0.001.\n",
    "* **metrics:** list of metrics passed to the Learner. Default=None.\n",
    "* **cbs:** list of callbacks passed to the Learner. Default=None.\n",
    "* **wd:** is the default weight decay used when training the model. Default=None.\n",
    "\n",
    "**Less frequently used arguments:**\n",
    "\n",
    "* **sel_vars:** used to select which of the features in multivariate datasets are used. Default=None means all features are used. If necessary a list-like of indices can be used (eg.`[0,3,5]`).\n",
    "* **sel_steps:** used to select the steps used. Default=None means all steps are used. If necessary a list-like of indices can be used (eg. `slice(-50, None)` will select the last 50 steps from each time series).\n",
    "* **weights:** indicates a sample weight per instance. Used to pass pass a probability to the train dataloader sampler. Samples with more weight will be selected more often during training. \n",
    "* **partial_n:** select randomly partial quantity of data at each epoch. Used to reduce the training size (for example for testing purposes). int or float can be used.\n",
    "* **train_metrics:** flag used to display metrics in the training set. Defaults to False.\n",
    "* **valid_metrics:** flag used to display metrics in the validtion set. Defaults to True.\n",
    "* **inplace:** indicates whether tfms are applied during instantiation or on-the-fly. Default=True, which means that tfms will be applied during instantiation. This results in a faster training, but it can only be used when data fits in memory. Otherwise set it to False. \n",
    "* **shuffle_train:** indicates whether to shuffle the training set every time the dataloader is fully read/iterated or not. This doesn't have an impact on the validation set which is never shuffled. Default=True.\n",
    "* **drop_last:** if True the last incomplete training batch is dropped (thus ensuring training batches of equal size). This doesn't have an impact on the validation set where samples are never dropped. Default=True.\n",
    "* **num_workers:** num_workers (int): how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. Default=None. \n",
    "* **do_setup:** ndicates if the Pipeline.setup method should be called during initialization. Default=True.\n",
    "* **device:** Defaults to default_device() which is CUDA by default. You can specify device as `torch.device('cpu').\n",
    "* **seed:** Set to an int to ensure reprodubibility. Default=None.\n",
    "* **verbose:** controls the verbosity when fitting and predicting.\n",
    "* **exclude_head:** indicates whether the head of the pretrained model needs to be removed or not. Default=True.\n",
    "* **cut:** indicates the position where the pretrained model head needs to be cut. Defaults=-1.\n",
    "* **init:** allows you to set to None (no initialization applied), set to True (in which case nn.init.kaiming_normal_ will be applied) or pass an initialization. Default=None.\n",
    "* **splitter:** To do transfer learning, you need to pass a splitter to Learner. This should be a function taking the model and returning a collection of parameter groups, e.g. a list of list of parameters. Default=trainable_params. If the model has a backbone and a head, it will then be split in those 2 groups.\n",
    "* **path** and **model_dir:** are used to save and/or load models. Often path will be inferred from dls, but you can override it or pass a Path object to model_dir.\n",
    "* **wd_bn_bias:** controls if weight decay is applied to BatchNorm layers and bias. Default=False.\n",
    "train_bn=True\n",
    "* **moms:** the default momentums used in Learner.fit_one_cycle. Default=(0.95, 0.85, 0.95)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export  \n",
    "class TSForecaster(Learner):\n",
    "    def __init__(self, X, y=None, splits=None, tfms=None, inplace=True, sel_vars=None, sel_steps=None, weights=None, partial_n=None, \n",
    "                 train_metrics=False, valid_metrics=True, bs=[64, 128], batch_size=None, batch_tfms=None, pipelines=None,\n",
    "                 shuffle_train=True, drop_last=True, num_workers=0, do_setup=True, device=None, seed=None,\n",
    "                 arch=None, arch_config={}, pretrained=False, weights_path=None, exclude_head=True, cut=-1, init=None,\n",
    "                 loss_func=None, opt_func=Adam, lr=0.001, metrics=None, cbs=None, wd=None, wd_bn_bias=False,\n",
    "                 train_bn=True, moms=(0.95, 0.85, 0.95),  path='.', model_dir='models', splitter=trainable_params, verbose=False):\n",
    "\n",
    "        # Seed\n",
    "        if seed is not None:\n",
    "            set_seed(seed, reproducible=True)\n",
    "        \n",
    "        # Batch size\n",
    "        if batch_size is not None:\n",
    "            bs = batch_size\n",
    "\n",
    "        # DataLoaders\n",
    "        dls = get_ts_dls(X, y=y, splits=splits, sel_vars=sel_vars, sel_steps=sel_steps, tfms=tfms, inplace=inplace, \n",
    "                         path=path, bs=bs, batch_tfms=batch_tfms, num_workers=num_workers, weights=weights, partial_n=partial_n, \n",
    "                         device=device, shuffle_train=shuffle_train, drop_last=drop_last)\n",
    "        \n",
    "        if loss_func is None:\n",
    "            if hasattr(dls, 'loss_func'): loss_func = dls.loss_func\n",
    "            elif hasattr(dls, 'cat') and not dls.cat: loss_func = MSELossFlat()\n",
    "            elif hasattr(dls, 'train_ds') and hasattr(dls.train_ds, 'loss_func'): loss_func = dls.train_ds.loss_func\n",
    "            else: loss_func = MSELossFlat()\n",
    "        \n",
    "        # Model\n",
    "        if isinstance(arch, nn.Module): \n",
    "            model = arch\n",
    "            if arch_config: \n",
    "                warnings.warn(\"You have passed arch_config to a model that is already intantiated. It will not have any effect.\", UserWarning)\n",
    "            if init is not None: \n",
    "                warnings.warn(\"You have passed init to a model that is already intantiated. It will not have any effect.\", UserWarning)\n",
    "        else:\n",
    "            if init is True:\n",
    "                init = nn.init.kaiming_normal_\n",
    "            if arch is None:\n",
    "                arch = InceptionTimePlus\n",
    "            elif isinstance(arch, str): arch = get_arch(arch)\n",
    "            # if 'xresnet' in arch.__name__.lower() and not '1d' in arch.__name__.lower():\n",
    "            #     model = build_tsimage_model(arch, dls=dls, pretrained=pretrained, init=init, device=device, verbose=verbose, arch_config=arch_config)\n",
    "            # elif 'tabularmodel' in arch.__name__.lower():\n",
    "            #     model = build_tabular_model(arch, dls=dls, device=device, arch_config=arch_config)\n",
    "            # else:\n",
    "            #     model = build_ts_model(arch, dls=dls, device=device, verbose=verbose, pretrained=pretrained, weights_path=weights_path,\n",
    "            #                        exclude_head=exclude_head, cut=cut, init=init, arch_config=arch_config)\n",
    "            model = build_ts_model(arch, dls=dls, device=device, verbose=verbose, pretrained=pretrained, weights_path=weights_path,\n",
    "                                exclude_head=exclude_head, cut=cut, init=init, arch_config=arch_config)\n",
    "        try:\n",
    "            setattr(model, \"__name__\", arch.__name__)\n",
    "        except:\n",
    "            setattr(model, \"__name__\", arch.__class__.__name__)\n",
    "        \n",
    "        if hasattr(model, \"backbone\") and hasattr(model, \"head\"):\n",
    "            splitter = ts_splitter\n",
    "            \n",
    "        if pipelines is not None:\n",
    "            pipelines = listify(pipelines)\n",
    "        setattr(self, \"pipelines\", pipelines)\n",
    "\n",
    "        super().__init__(dls, model, loss_func=loss_func, opt_func=opt_func, lr=lr, cbs=cbs, metrics=metrics, path=path, splitter=splitter,\n",
    "                         model_dir=model_dir, wd=wd, wd_bn_bias=wd_bn_bias, train_bn=train_bn, moms=moms)\n",
    "        \n",
    "        if hasattr(self, \"recorder\"):\n",
    "            self.recorder.train_metrics = train_metrics\n",
    "            if splits is None or not hasattr(splits[0], \"__len__\") or len(splits) == 1 or \\\n",
    "                (len(splits) >= 2 and (splits[1] is None or not hasattr(splits[1], \"__len__\"))): \n",
    "                self.recorder.valid_metrics = False\n",
    "            else:\n",
    "                self.recorder.valid_metrics = valid_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.data.preparation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Sunspots\n",
      "downloading data...\n",
      "...done. Path = data/forecasting/Sunspots.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ts = get_forecasting_time_series('Sunspots')\n",
    "if ts is not None: # This is to prevent a test fail when the data server is not available\n",
    "    X, y = SlidingWindowSplitter(60, horizon=1)(ts)\n",
    "    splits = TSSplitter(235)(y)\n",
    "    batch_tfms = [TSStandardize(by_var=True)]\n",
    "    learn = TSForecaster(X, y, splits=splits, batch_tfms=batch_tfms, arch=None, arch_config=dict(fc_dropout=.5), metrics=mae, bs=512, \n",
    "                         partial_n=.1, train_metrics=True)\n",
    "    learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=torch.rand(8,2,50)\n",
    "y=torch.rand(8,1)\n",
    "splits = TimeSplitter(show_plot=False)(y)\n",
    "\n",
    "fail_test = []\n",
    "for arch in all_arch_names:\n",
    "    if not \"plus\" in arch.lower(): continue\n",
    "    try:\n",
    "        fcst = TSForecaster(X, y, splits=splits, arch=arch, metrics=mse)\n",
    "        with ContextManagers([fcst.no_bar(), fcst.no_logging()]):\n",
    "            fcst.fit_one_cycle(1, 1e-3)\n",
    "    except Exception as e: \n",
    "        fail_test.append(arch)\n",
    "        print(arch, e)\n",
    "\n",
    "test_eq(fail_test, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.save_checkpoint();",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nacho/notebooks/tsai/nbs/022_tslearner.ipynb saved at 2023-04-01 18:12:55\n",
      "Correct notebook to script conversion! 😃\n",
      "Saturday 01/04/23 18:13:00 CEST\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|eval: false\n",
    "#|hide\n",
    "from tsai.export import get_nb_name; nb_name = get_nb_name(locals())\n",
    "from tsai.imports import create_scripts; create_scripts(nb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
