{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting CSV Files to LAS Files Using LASIO\n",
    "*Created by: Andy McDonald*  \n",
    "*Article Version:*  \n",
    "*YouTube Video:*  \n",
    "\n",
    "Well log data can be delivered in a variety of formats (DLIS, LAS, CSV, ASC etc.). however, if you have a CSV file containing well log data, and you want to convert it to LAS format there are a number of ways you can achieve this. So if you want to see how to do it using the LASIO library then keep watching.\n",
    "\n",
    "One of the issues you may come across when looking at well log data is the large variety of data formats. Data can be delivered or stored in DLIS files, LAS Files, CSV Files and many other different formats. This can often become a headache trying to work out which file to use or when you come to creating a standard file that can be easily read by commercial software or by other users.\n",
    "\n",
    "It is a simple format and it is a flat file that contains meta data about the well within the header section, and parameter information, as well as the log data measurements. These files are easy to open up in any text editor and you can quickly and easily read the content. \n",
    "\n",
    "However there may be occasions where you end up with a CSV file containing well log measurements and you want to convert it to a LAS file. Well, that is what we are going cover in todays video. \n",
    "\n",
    "We are going to see how we can take a simple CSV file like this and convert it to a LAS file like this using the excellent LASIO library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Required Libraries\n",
    "First off, we will load in the required python libraries. For this tutorial we will be using lasio and pandas.\n",
    "\n",
    "For more information about using lasio, check out this article here: https://andymcdonaldgeo.medium.com/loading-and-displaying-well-log-data-b9568efd1d8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lasio\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in CSV File Using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to load in our csv file.\n",
    "This is done using the `read_csv()` function from pandas and passing in the file location and file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/Notebook 22/Notebook 22 - VOLVE - 15_9-19.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the file has been read, we can then check what the contents of the file are  by calling upon the pandas `.head()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>CALI</th>\n",
       "      <th>COAL</th>\n",
       "      <th>DT</th>\n",
       "      <th>DT_LOG</th>\n",
       "      <th>DTS</th>\n",
       "      <th>DTS_LOG</th>\n",
       "      <th>GR</th>\n",
       "      <th>NPHI</th>\n",
       "      <th>PHIE</th>\n",
       "      <th>PHIEC</th>\n",
       "      <th>PHIT</th>\n",
       "      <th>PHITC</th>\n",
       "      <th>RHOB</th>\n",
       "      <th>RHOB_LOG</th>\n",
       "      <th>RT</th>\n",
       "      <th>RW</th>\n",
       "      <th>TEMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3500.0183</td>\n",
       "      <td>9.315</td>\n",
       "      <td>0</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>157.1754</td>\n",
       "      <td>157.1754</td>\n",
       "      <td>36.621</td>\n",
       "      <td>0.1542</td>\n",
       "      <td>0.1122</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>2.4602</td>\n",
       "      <td>2.460</td>\n",
       "      <td>1.791</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>94.5855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3500.1707</td>\n",
       "      <td>9.324</td>\n",
       "      <td>0</td>\n",
       "      <td>77.2473</td>\n",
       "      <td>77.2473</td>\n",
       "      <td>158.9566</td>\n",
       "      <td>158.9566</td>\n",
       "      <td>36.374</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.1159</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>2.4680</td>\n",
       "      <td>2.468</td>\n",
       "      <td>1.756</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>94.5897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3500.3231</td>\n",
       "      <td>9.338</td>\n",
       "      <td>0</td>\n",
       "      <td>77.8462</td>\n",
       "      <td>77.8462</td>\n",
       "      <td>159.7642</td>\n",
       "      <td>159.7642</td>\n",
       "      <td>30.748</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>0.1082</td>\n",
       "      <td>0.1079</td>\n",
       "      <td>0.1127</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>2.4730</td>\n",
       "      <td>2.473</td>\n",
       "      <td>1.720</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>94.5940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3500.4755</td>\n",
       "      <td>9.329</td>\n",
       "      <td>0</td>\n",
       "      <td>78.3571</td>\n",
       "      <td>78.3571</td>\n",
       "      <td>158.7547</td>\n",
       "      <td>158.7547</td>\n",
       "      <td>29.795</td>\n",
       "      <td>0.1767</td>\n",
       "      <td>0.1254</td>\n",
       "      <td>0.1226</td>\n",
       "      <td>0.1292</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>2.4471</td>\n",
       "      <td>2.447</td>\n",
       "      <td>1.696</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>94.5982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3500.6279</td>\n",
       "      <td>9.328</td>\n",
       "      <td>0</td>\n",
       "      <td>78.6560</td>\n",
       "      <td>78.6560</td>\n",
       "      <td>157.1320</td>\n",
       "      <td>157.1320</td>\n",
       "      <td>27.346</td>\n",
       "      <td>0.1662</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.1299</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>2.4460</td>\n",
       "      <td>2.446</td>\n",
       "      <td>1.697</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>94.6025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DEPTH   CALI  COAL       DT   DT_LOG       DTS   DTS_LOG      GR  \\\n",
       "0  3500.0183  9.315     0  76.7292  76.7292  157.1754  157.1754  36.621   \n",
       "1  3500.1707  9.324     0  77.2473  77.2473  158.9566  158.9566  36.374   \n",
       "2  3500.3231  9.338     0  77.8462  77.8462  159.7642  159.7642  30.748   \n",
       "3  3500.4755  9.329     0  78.3571  78.3571  158.7547  158.7547  29.795   \n",
       "4  3500.6279  9.328     0  78.6560  78.6560  157.1320  157.1320  27.346   \n",
       "\n",
       "     NPHI    PHIE   PHIEC    PHIT   PHITC    RHOB  RHOB_LOG     RT      RW  \\\n",
       "0  0.1542  0.1122  0.1098  0.1209  0.1186  2.4602     2.460  1.791  0.0211   \n",
       "1  0.1694  0.1074  0.1060  0.1159  0.1146  2.4680     2.468  1.756  0.0211   \n",
       "2  0.1776  0.1082  0.1079  0.1127  0.1125  2.4730     2.473  1.720  0.0211   \n",
       "3  0.1767  0.1254  0.1226  0.1292  0.1264  2.4471     2.447  1.696  0.0211   \n",
       "4  0.1662  0.1278  0.1249  0.1299  0.1270  2.4460     2.446  1.697  0.0211   \n",
       "\n",
       "      TEMP  \n",
       "0  94.5855  \n",
       "1  94.5897  \n",
       "2  94.5940  \n",
       "3  94.5982  \n",
       "4  94.6025  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that we have 18 columns within our dataframe, and a mixture of well log measurements.\n",
    "\n",
    "To ensure that the data is all numeric and to understand how many nulls are present within the data we can call upon the pandas function `.info()`. This is not a necessary step, but it does allow us to check that the columns are numeric (either float64 or int64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4101 entries, 0 to 4100\n",
      "Data columns (total 18 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   DEPTH     4101 non-null   float64\n",
      " 1   CALI      4101 non-null   float64\n",
      " 2   COAL      4101 non-null   int64  \n",
      " 3   DT        4101 non-null   float64\n",
      " 4   DT_LOG    4101 non-null   float64\n",
      " 5   DTS       4101 non-null   float64\n",
      " 6   DTS_LOG   4101 non-null   float64\n",
      " 7   GR        4068 non-null   float64\n",
      " 8   NPHI      4100 non-null   float64\n",
      " 9   PHIE      4101 non-null   float64\n",
      " 10  PHIEC     4101 non-null   float64\n",
      " 11  PHIT      4101 non-null   float64\n",
      " 12  PHITC     4101 non-null   float64\n",
      " 13  RHOB      4101 non-null   float64\n",
      " 14  RHOB_LOG  4101 non-null   float64\n",
      " 15  RT        4101 non-null   float64\n",
      " 16  RW        4101 non-null   float64\n",
      " 17  TEMP      4101 non-null   float64\n",
      "dtypes: float64(17), int64(1)\n",
      "memory usage: 576.8 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Empty LAS Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can transfer our data from CSV to LAS, we first need to create a blank LAS file. This is achieved by calling upon `lasio.LASFile()` and assigning it to a variable. In this example the variable is called `las_file`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "las_file = lasio.LASFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we try to view the contents of the newly created LAS file we can see that the header information is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Version': [HeaderItem(mnemonic=\"VERS\", unit=\"\", value=\"2.0\", descr=\"CWLS log ASCII Stan...),\n",
       "  HeaderItem(mnemonic=\"WRAP\", unit=\"\", value=\"NO\", descr=\"One line per depth s...),\n",
       "  HeaderItem(mnemonic=\"DLM\", unit=\"\", value=\"SPACE\", descr=\"Column Data Sectio...)],\n",
       " 'Well': [HeaderItem(mnemonic=\"STRT\", unit=\"m\", value=\"nan\", descr=\"START DEPTH\"),\n",
       "  HeaderItem(mnemonic=\"STOP\", unit=\"m\", value=\"nan\", descr=\"STOP DEPTH\"),\n",
       "  HeaderItem(mnemonic=\"STEP\", unit=\"m\", value=\"nan\", descr=\"STEP\"),\n",
       "  HeaderItem(mnemonic=\"NULL\", unit=\"\", value=\"-9999.25\", descr=\"NULL VALUE\"),\n",
       "  HeaderItem(mnemonic=\"COMP\", unit=\"\", value=\"\", descr=\"COMPANY\"),\n",
       "  HeaderItem(mnemonic=\"WELL\", unit=\"\", value=\"\", descr=\"WELL\"),\n",
       "  HeaderItem(mnemonic=\"FLD\", unit=\"\", value=\"\", descr=\"FIELD\"),\n",
       "  HeaderItem(mnemonic=\"LOC\", unit=\"\", value=\"\", descr=\"LOCATION\"),\n",
       "  HeaderItem(mnemonic=\"PROV\", unit=\"\", value=\"\", descr=\"PROVINCE\"),\n",
       "  HeaderItem(mnemonic=\"CNTY\", unit=\"\", value=\"\", descr=\"COUNTY\"),\n",
       "  HeaderItem(mnemonic=\"STAT\", unit=\"\", value=\"\", descr=\"STATE\"),\n",
       "  HeaderItem(mnemonic=\"CTRY\", unit=\"\", value=\"\", descr=\"COUNTRY\"),\n",
       "  HeaderItem(mnemonic=\"SRVC\", unit=\"\", value=\"\", descr=\"SERVICE COMPANY\"),\n",
       "  HeaderItem(mnemonic=\"DATE\", unit=\"\", value=\"\", descr=\"DATE\"),\n",
       "  HeaderItem(mnemonic=\"UWI\", unit=\"\", value=\"\", descr=\"UNIQUE WELL ID\"),\n",
       "  HeaderItem(mnemonic=\"API\", unit=\"\", value=\"\", descr=\"API NUMBER\")],\n",
       " 'Curves': [],\n",
       " 'Parameter': [],\n",
       " 'Other': ''}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "las_file.header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also confirm that we have no data within the file by calling upon `las_file.curves`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "las_file.curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Metadata\n",
    "Now that we have a blank las object to work with, we now need to add information to our LAS header. \n",
    "\n",
    "The first step is to create a number of variables that we want to fill in. Doing it this way, rather than passing them into the HeaderItem functions makes it easier to change them in the future and also makes it more readable. For instance, if we created a function where we wanted to update specifc parameters within the header based on different files, we can easily pass these variables into the function and we won't have to update the code within the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_name = 'Random Well'\n",
    "field_name = 'Random Field'\n",
    "uwi = '123456789'\n",
    "country = 'Random Country'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin assigning the values to the header, we need to call upon `las_file.well` and select the header attribute we want to add to. On the right hand side, we will update the HeaderItem and supply a value to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "las_file.well['WELL'] = lasio.HeaderItem('WELL', value=well_name)\n",
    "las_file.well['FLD'] = lasio.HeaderItem('FLD', value=field_name)\n",
    "las_file.well['UWI'] = lasio.HeaderItem('UWI', value=uwi)\n",
    "las_file.well['CTRY'] = lasio.HeaderItem('CTRY', value=country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have done this we can call upon our header again and we can now see that the values for the well name, UWI, country and field name have all been updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Version': [HeaderItem(mnemonic=\"VERS\", unit=\"\", value=\"2.0\", descr=\"CWLS log ASCII Stan...),\n",
       "  HeaderItem(mnemonic=\"WRAP\", unit=\"\", value=\"NO\", descr=\"One line per depth s...),\n",
       "  HeaderItem(mnemonic=\"DLM\", unit=\"\", value=\"SPACE\", descr=\"Column Data Sectio...)],\n",
       " 'Well': [HeaderItem(mnemonic=\"STRT\", unit=\"m\", value=\"nan\", descr=\"START DEPTH\"),\n",
       "  HeaderItem(mnemonic=\"STOP\", unit=\"m\", value=\"nan\", descr=\"STOP DEPTH\"),\n",
       "  HeaderItem(mnemonic=\"STEP\", unit=\"m\", value=\"nan\", descr=\"STEP\"),\n",
       "  HeaderItem(mnemonic=\"NULL\", unit=\"\", value=\"-9999.25\", descr=\"NULL VALUE\"),\n",
       "  HeaderItem(mnemonic=\"COMP\", unit=\"\", value=\"\", descr=\"COMPANY\"),\n",
       "  HeaderItem(mnemonic=\"WELL\", unit=\"\", value=\"Random Well\", descr=\"\"),\n",
       "  HeaderItem(mnemonic=\"FLD\", unit=\"\", value=\"Random Field\", descr=\"\"),\n",
       "  HeaderItem(mnemonic=\"LOC\", unit=\"\", value=\"\", descr=\"LOCATION\"),\n",
       "  HeaderItem(mnemonic=\"PROV\", unit=\"\", value=\"\", descr=\"PROVINCE\"),\n",
       "  HeaderItem(mnemonic=\"CNTY\", unit=\"\", value=\"\", descr=\"COUNTY\"),\n",
       "  HeaderItem(mnemonic=\"STAT\", unit=\"\", value=\"\", descr=\"STATE\"),\n",
       "  HeaderItem(mnemonic=\"CTRY\", unit=\"\", value=\"Random Country\", descr=\"\"),\n",
       "  HeaderItem(mnemonic=\"SRVC\", unit=\"\", value=\"\", descr=\"SERVICE COMPANY\"),\n",
       "  HeaderItem(mnemonic=\"DATE\", unit=\"\", value=\"\", descr=\"DATE\"),\n",
       "  HeaderItem(mnemonic=\"UWI\", unit=\"\", value=\"123456789\", descr=\"\"),\n",
       "  HeaderItem(mnemonic=\"API\", unit=\"\", value=\"\", descr=\"API NUMBER\")],\n",
       " 'Curves': [],\n",
       " 'Parameter': [],\n",
       " 'Other': ''}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "las_file.header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Curves\n",
    "To add curves to the file we can use the `add_curve` function and pass in the data and units.\n",
    "\n",
    "This example here shows how we can add a single curve to the file called DEPT. Note that if adding the main depth data, it does need to go in as DEPT rather than DEPTH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "las_file.add_curve('DEPT', data['DEPTH'], unit='m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write out our file, we can call upon `.write()` and pass in the location and file name for our LAS file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "las_file.write('Output/Notebook 22/OutputLAS.las')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Remaining Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reuse the file that we have created above and write the remaining curves.\n",
    "\n",
    "To make things easier, I have created a list containing the measurement units for each well log curve. Note that this does include the depth measurement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = ['m',\n",
    " 'inches',\n",
    " 'unitless',\n",
    " 'us/ft',\n",
    " 'us/ft',\n",
    " 'us/ft',\n",
    " 'us/ft',\n",
    " 'API',\n",
    " 'v/v_decimal',\n",
    " 'v/v_decimal',\n",
    " 'v/v_decimal',\n",
    " 'v/v_decimal',\n",
    " 'v/v_decimal',\n",
    " 'g/cm3',\n",
    " 'g/cm3',\n",
    " 'ohm.m',\n",
    " 'ohm.m',\n",
    " 'degC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then begin to loop through each of the logging measurements / columns within the dataframe along with the units list. This is achieved using the Python `zip` function.\n",
    "\n",
    "As we already have depth within our las file, we can skip this column by checking the column name. There are other ways in which this can be handled, for example by writing the depth and curves to the las file in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, unit in zip(data.columns, units):\n",
    "    if col != 'DEPTH':\n",
    "        las_file.add_curve(col, data[col], unit=unit)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we check the `curves` function, we can see that we have all of our curves and they all have the appropriate units. We can also see from the data.shape part of the listing we have 4101 values per curve which confirms we have data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CurveItem(mnemonic=\"DEPT\", unit=\"m\", value=\"\", descr=\"\", original_mnemonic=\"DEPT\", data.shape=(4101,)),\n",
       " CurveItem(mnemonic=\"CALI\", unit=\"unitless\", value=\"\", descr=\"\", original_mnemonic=\"CALI\", data.shape=(4101,)),\n",
       " CurveItem(mnemonic=\"COAL\", unit=\"us/ft\", value=\"\", descr=\"\", original_mnemonic=\"COAL\", data.shape=(4101,)),\n",
       " CurveItem(mnemonic=\"DT\", unit=\"us/ft\", value=\"\", descr=\"\", original_mnemonic=\"DT\", data.shape=(4101,)),\n",
       " CurveItem(mnemonic=\"DT_LOG\", unit=\"us/ft\", value=\"\", descr=\"\", original_mnemonic=\"DT_LOG\", data.shape=(4101,)),\n",
       " CurveItem(mnemonic=\"DTS\", unit=\"us/ft\", value=\"\", descr=\"\", original_mnemonic=\"DTS\", data.shape=(4101,)),\n",
       " CurveItem(mnemonic=\"DTS_LOG\", unit=\"API\", value=\"\", descr=\"\", original_mnemonic=\"DTS_LOG\", data.shape=(4101,)),\n",
       " CurveItem(mnemonic=\"GR\", unit=\"v/v_decimal\", value=\"\", descr=\"\", original_mnemonic=\"GR\", data.shape=(4101,)),\n",
       " CurveItem(mnemonic=\"NPHI\", unit=\"v/v_decimal\", value=\"\", descr=\"\", original_mnemonic=\"NPHI\", data.shape=(4101,)),\n",
       " CurveItem(mnemonic=\"PHIE\", unit=\"v/v_decimal\", value=\"\", descr=\"\", original_mnemonic=\"PHIE\", data.shape=(4101,)),\n",
       " CurveItem(mnemonic=\"PHIEC\", unit=\"v/v_decimal\", value=\"\", descr=\"\", original_mnemonic=\"PHIEC\", data.shape=(4101,)),\n",
       " CurveItem(mnemonic=\"PHIT\", unit=\"v/v_decimal\", value=\"\", descr=\"\", original_mnemonic=\"PHIT\", data.shape=(4101,)),\n",
       " CurveItem(mnemonic=\"PHITC\", unit=\"g/cm3\", value=\"\", descr=\"\", original_mnemonic=\"PHITC\", data.shape=(4101,)),\n",
       " CurveItem(mnemonic=\"RHOB\", unit=\"g/cm3\", value=\"\", descr=\"\", original_mnemonic=\"RHOB\", data.shape=(4101,)),\n",
       " CurveItem(mnemonic=\"RHOB_LOG\", unit=\"ohm.m\", value=\"\", descr=\"\", original_mnemonic=\"RHOB_LOG\", data.shape=(4101,)),\n",
       " CurveItem(mnemonic=\"RT\", unit=\"ohm.m\", value=\"\", descr=\"\", original_mnemonic=\"RT\", data.shape=(4101,)),\n",
       " CurveItem(mnemonic=\"RW\", unit=\"degC\", value=\"\", descr=\"\", original_mnemonic=\"RW\", data.shape=(4101,))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "las_file.curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm that we have values by calling upon of the curves. In the example below, I have called upon GR, and we get an array returned containing the Gamma Ray values, which match the values in the dataframe presented earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  36.621,   36.374,   30.748, ..., -999.   , -999.   , -999.   ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "las_file['GR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are happy with the las file, we can now export it to a file and use it in any other software package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "las_file.write('Output/Notebook 22/OutputLAS_FINAL.las')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In this article we have covered how to convert a simple CSV file containing well log / petrophysical measurements into a industry standard LAS (Log ASCII Standard) file. Once you have created a blank LASFile object in lasio, you will be able to manually update the header items with the correct metadata and also update the curves with the correct values.\n",
    "\n",
    "***Thanks for reading!***\n",
    "\n",
    "*If you have found this article useful, please feel free to check out my other articles looking at various aspects of Python and well log data. You can also find my code used in this article and others at [GitHub](https://github.com/andymcdgeo).*\n",
    "\n",
    "*If you want to get in touch you can find me on [LinkedIn](https://www.linkedin.com/in/andymcdonaldgeo/) or at my [website](http://andymcdonald.scot/).*\n",
    "\n",
    "*Interested in learning more about python and well log data or petrophysics? Follow me on [Medium](https://medium.com/@andymcdonaldgeo).*\n",
    "\n",
    "If you have enjoyed this article or any others and want to show your appreciate you are welcome to [Buy Me a Coffee](https://www.buymeacoffee.com/andymcdonaldgeo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
